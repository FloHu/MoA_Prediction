---
title: "Predicting drug mode of action: Defining sampling instances"
author: "Florian Huber, Leonard Dubois"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

# Setup

```{r setup}
# function to check if a package is installed, if so, load it, else install and then load it
source("./R/ipak.R")
# set chunk options and load libraries
source("./setup.R")
# custom functions
walk(list.files("./R", pattern = "*.R", full.names = T), source)

load(file = "data/the_matrix_newDrugs.RData")
load(file = "data/matrix_container.RData")
```


# Aim of notebook: defining sampling instances - motivation

In order to compare performances of different models (e.g. Random Forest, Boosting trees...), one has 
to use the *exact same samples in every fold* (inner and outer) of the nested cross-validation.

The function `makeResampleInstance()` could be used to keep in memory a object containing details 
on the sampling. For a 5-fold by 5-fold nested cross-validation, 6 resampling instances are needed : 
one for each inner fold and one for the outer loop. In particular, instances of the inner fold should 
be based on the training sets defined in the outer loop instances.

Even if such a strategy can't be avoided in order to obtain an unbiased comparison of models, it 
still presents some weaknesses : one can easily argue that the choosen instances are the ones giving 
the best performances. To prevent such criticism, a repeated cross validation is possible, e.g. 
10 times. 

Thus, the exact strategy for assessing models' performances and comparing them could be called : 
**Repeated nested cross-validation with instanced stratified resampling**


## Generating instances

Since we have a small data set, it is actually better to use more folds. Thus, the training set will 
contain more individuals. The testing set results can be concatenated afterwards, with each individual 
having been predicted by a model in which it was not trained. 

A bunch of getters and test functions

```{r}

get_outer_train_ids = function(NCV_sampling, rep_nb){
    NCV_sampling[[rep_nb]]$outer$train.inds
}

get_inner_train_ids = function(NCV_sampling, rep_nb, outer_nb){
    NCV_sampling[[rep_nb]]$inner[[outer_nb]]$train.inds
}

```

```{r function}

#Makes more sense to put it here than in a seperate file
instance_creation = function(dataset, printTest = F, nFoldsOuter = 8, nFoldsInner = 8){
    dataset = select(dataset, -drugname_typaslab)
    sampling_method = makeResampleDesc(method = "CV", iters = nFoldsOuter, stratify = TRUE)
    
    # outer instance
    outer_task =  makeClassifTask(data = dataset, target = "process_broad")
    sample_instance_outer =  makeResampleInstance(sampling_method, outer_task)
    
    if(printTest){
        # Testing stratification of outer instance
        for(i in 1:nFoldsOuter){
            cat("Fold", i, "- Train and test sets\n" )
            ind = sample_instance_outer$train.inds[[i]]
            print(table(dataset[ind, "process_broad"]))
            ind = sample_instance_outer$test.inds[[i]]
            print(table(dataset[ind, "process_broad"]))
        }
    }
    
    # defining inner instances
    sampling_method = makeResampleDesc(method = "CV", iters = nFoldsInner, stratify = TRUE)
    sample_instance_inner = list()
    for(i in 1:nFoldsOuter){
        # New task using a subset of the whole dataset defined by outer training set ID
        inner_task = makeClassifTask(data = dataset[ sample_instance_outer$train.inds[[i]] , ], target = "process_broad")
        sample_instance_inner[[i]] = makeResampleInstance(sampling_method, inner_task)
    }
    
    if(printTest){
        # Testing stratification of inner instances
        # BE CAREFUL !!!
        # Indexes of individuals in the inner fold are the indexes of the vector of indexes of the corresponding outer fold 
        for (j in 1:nFoldsOuter ){
            outer_ind = sample_instance_outer$train.inds[[j]]
            cat("Outer fold", j, "\n")
            print(table(dataset[outer_ind, "process_broad"] ))
            cat("Inner folds \n")
            for (i in 1:nFoldsInner){
                ind = c(sample_instance_inner[[j]]$train.inds[[i]], sample_instance_inner[[j]]$test.inds[[i]])
                print(table(dataset[outer_ind[ind], "process_broad"]))
            }
        }
    }
    
    nested_CV_instance = list(outer = sample_instance_outer, inner = sample_instance_inner)
    return(nested_CV_instance)
}

```

## Creation of repeated CV instance - NEW LABELS

Creation of instances based on Nassos correction from 05/08/2018

```{r echo = F }

# the_matrix_newDrugs = mutate(the_matrix_newDrugs, process_broad = replace(process_broad, process_broad %in% c("oxidative_stress", "pmf", "protein_qc"), "other"))

Rep_Nest_CV_instance_newDrugs = list()
dataset_newDrugs = filter(matrix_container, drug_dosages != "all") %>% select(drug_feature_matrices) %>% `[[`(1,1)
dataset_newDrugs = mutate(dataset_newDrugs, process_broad = replace(process_broad, process_broad %in% c("oxidative_stress", "pmf", "protein_qc"), "other"))
for(i in 1:10){
    name = paste("NCV_", as.character(i), sep="")
    Rep_Nest_CV_instance_newDrugs[[name]] = instance_creation(dataset = dataset_newDrugs, printTest = F)
}

```

## Expanding resampling instance to all dosages

```{r}
# The idea here is to copy the resampling object and map individuals ids from the newDrug dataset to the drugs names 
# and then remap the names to the individuals ids of the allDosage dataset

# One should also make the size fields in the lists match the length of vector of IDS

dataset_allDosage = filter(matrix_container, drug_dosages == "all") %>% select(drug_feature_matrices) %>% `[[`(1,1)
dataset_allDosage = mutate(dataset_allDosage, process_broad = replace(process_broad, process_broad %in% c("oxidative_stress", "pmf", "protein_qc"), "other"))

Rep_Nest_CV_instance_allDosage = Rep_Nest_CV_instance_newDrugs

# For each repetition
for(i in 1:length(Rep_Nest_CV_instance_allDosage)){
    
    # OUTER FOLD RESAMPLING MAPPING
    # === Training sets ===
    # drugNameSet = name of individuals/drugs in the training set
    drugNameSet_outer_train = map(get_outer_train_ids(Rep_Nest_CV_instance_newDrugs, rep_nb = i), function(x){dataset_newDrugs[x, "drugname_typaslab"]})
    # then get all ids linked to these name in the "raw" dataset
    allDosage_indexes = map(drugNameSet_outer_train, function(x){ which(dataset_allDosage$drugname_typaslab %in% x$drugname_typaslab) } )
    Rep_Nest_CV_instance_allDosage[[i]]$outer$train.inds = allDosage_indexes 
    # === Testing sets ===
    allDosage_indexes_test = map(allDosage_indexes, function(x){ setdiff(seq(1, nrow(dataset_allDosage)), x ) } )
    Rep_Nest_CV_instance_allDosage[[i]]$outer$test.inds = allDosage_indexes_test
    #Size
    Rep_Nest_CV_instance_allDosage[[i]]$outer$size = nrow(dataset_allDosage)
    
    # write TRUE to check in details
    if(FALSE){
        print(Rep_Nest_CV_instance_allDosage[[i]]$outer$train.inds)
        a = map(Rep_Nest_CV_instance_allDosage[[i]]$outer$train.inds, function(x){ unique(dataset_allDosage[x , ]$drugname_typaslab) })
        b = map(Rep_Nest_CV_instance_newDrugs[[i]]$outer$train.inds, function(x){ dataset_newDrugs[x , ]$drugname_typaslab })
        print(map2(.x = a, .y = b, .f = function(x,y) {print(setdiff(y,x))}))
    }

    
    # NEVER MAP INNER IDS DIRECTLY TO THE DATASET, ALWAYS MAP THEM FIRST TO OUTER ID  !!!
    
    # INNER FOLDS RESAMPLING MAPPING
    for(outer in 1:length(get_outer_train_ids(Rep_Nest_CV_instance_newDrugs, rep_nb = i))) {
        
        # === Training sets ===
        innerID = get_inner_train_ids(NCV_sampling = Rep_Nest_CV_instance_newDrugs, rep_nb = i, outer_nb = outer)
        outerID = get_outer_train_ids(NCV_sampling = Rep_Nest_CV_instance_newDrugs, rep_nb = i)[[outer]]
        innerID_to_rawData = map(.x = innerID, .f = function(x){ outerID[x]})
        
        drugNameSet_inner_train = map(innerID_to_rawData, function(x){dataset_newDrugs[x, "drugname_typaslab"]})
        # Here we got names of the drugs that should be in the inner training sets
        
        
        # Extract a subset of raw dataset based on outer training id and select names of this subset
        dataset_outer_train = dataset_allDosage[get_outer_train_ids(NCV_sampling = Rep_Nest_CV_instance_allDosage, rep_nb = i)[[outer]], ]$drugname_typaslab

        allDosage_indexes = map(drugNameSet_inner_train, function(x){ 
            which(dataset_outer_train %in% x$drugname_typaslab) 
        } )

        Rep_Nest_CV_instance_allDosage[[i]]$inner[[outer]]$train.inds = allDosage_indexes  

        
        if(FALSE){
            print(Rep_Nest_CV_instance_allDosage[[i]]$inner[[outer]]$train.inds)
            
            allDosageName_inner = map(.x = get_inner_train_ids(NCV_sampling = Rep_Nest_CV_instance_allDosage, rep_nb = i, outer_nb = outer),
                                      .f = function(x) {
                                          unique(dataset_allDosage[(get_outer_train_ids(Rep_Nest_CV_instance_allDosage, rep_nb = i)[[outer]])[x], ]$drugname_typaslab)
                                      })
            newDrugsName_inner = map(.x = get_inner_train_ids(NCV_sampling = Rep_Nest_CV_instance_newDrugs, rep_nb = i, outer_nb = outer),
                                      .f = function(x) {
                                          unique(dataset_newDrugs[(get_outer_train_ids(Rep_Nest_CV_instance_newDrugs, rep_nb = i)[[outer]])[x], ]$drugname_typaslab)
                                      })
            print(map2(.x = allDosageName_inner, .y = newDrugsName_inner, .f = function(x,y) {print(setdiff(y, x))}))
        }
        
        # === Testing sets ===
        allDosage_indexes_test = map(allDosage_indexes, function(x){ setdiff(seq(1, length(dataset_outer_train)), x ) } )
        Rep_Nest_CV_instance_allDosage[[i]]$inner[[outer]]$test.inds = allDosage_indexes_test
        Rep_Nest_CV_instance_allDosage[[i]]$inner[[outer]]$size = length(dataset_outer_train)
      
    }
}


# === NOTA BENE ===
# With this tricky resampling strategy, the same drugs are in the exact same sets in both cases (with or whithout all dosages)
# Only difference is that using all dosage, drugs are in a way present multiple times
# ================

```


# Resampling instance - 2 mostIA dosages + main MoA

Load the matrix, get rid of doubles, run once the instance creation and run again the chunk above.

```{r}

matrix_2mostia_mainMoa = readRDS(file = "data/matrix_2mostia_mainMoA.rds")
Rep_Nest_CV_instance = list()
unique_pos = match(unique(matrix_2mostia_mainMoa$drugname_typaslab), matrix_2mostia_mainMoa$drugname_typaslab)
dataset = matrix_2mostia_mainMoa[unique_pos, ] 


for(i in 1:10){
    name = paste("NCV_", as.character(i), sep="")
    Rep_Nest_CV_instance[[name]] = instance_creation(dataset = dataset, printTest = F)
}


# Then run : 
dataset_allDosage = matrix_2mostia_mainMoa
dataset_newDrugs = dataset
Rep_Nest_CV_instance_newDrugs = Rep_Nest_CV_instance
Rep_Nest_CV_instance_allDosage = Rep_Nest_CV_instance_newDrugs

# And then run the for loop of the chunk above. It is clearly not the most convenient way. The chunk wasn't suposed to be used multiple times when it was written...

saveRDS(object = Rep_Nest_CV_instance_allDosage, file = "data/RNCV_instance_2mostia_mainMoa.rds")

```


# Testing chunks - print class repartition inside Folds

Just to be sure...The amount of each class in an inner set and the corresponding training set of the outer fold should be the same.

```{r eval = F}
#Test of outer folds, if they are all differents
a = list()
for (i in 1:10){
    a[[i]] = Rep_Nest_CV_instance[[i]]$outer$train.inds
}

a = unlist(a, recursive = F)

res = c()
for (i in 1:30){
    for(j in 1:30){
        if(i != j){
            res = c(res, length(unlist(setdiff(a[i], a[j]))) )
        }
    }
}

```



```{r export data}
save(Rep_Nest_CV_instance_newDrugs, file = "data/Rep_Nest_CV_instance_newDrugs.RData")
save(Rep_Nest_CV_instance_allDosage, file = "data/Rep_Nest_CV_instance_allDosage.RData")
```


# System and session info

```{r}
R.Version
sessionInfo()
```
