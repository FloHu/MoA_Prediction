---
title: "Predicting drug mode of action: Defining sampling instances"
author: "Florian Huber, Leonard Dubois"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

# Setup

```{r setup}
# function to check if a package is installed, if so, load it, else install and then load it
source("./R/ipak.R")
# set chunk options and load libraries
source("./setup.R")
# custom functions
walk(list.files("./R", pattern = "*.R", full.names = T), source)

load(file = "data/the_matrix_newDrugs.RData")
load(file = "data/matrix_container.RData")
```


# Aim of notebook: defining sampling instances - motivation

In order to compare performances of different models (e.g. Random Forest, Boosting trees...), one has 
to use the *exact same samples in every fold* (inner and outer) of the nested cross-validation.

The function `makeResampleInstance()` could be used to keep in memory a object containing details 
on the sampling. For a 5-fold by 5-fold nested cross-validation, 6 resampling instances are needed : 
one for each inner fold and one for the outer loop. In particular, instances of the inner fold should 
be based on the training sets defined in the outer loop instances.

Even if such a strategy can't be avoided in order to obtain an unbiased comparison of models, it 
still presents some weaknesses : one can easily argue that the choosen instances are the ones giving 
the best performances. To prevent such criticism, a repeated cross validation is possible, e.g. 
10 times. 

Thus, the exact strategy for assessing models' performances and comparing them could be called : 
**Repeated nested cross-validation with instanced stratified resampling**


## Generating instances

Since we have a small data set, it is actually better to use more folds. Thus, the training set will 
contain more individuals. The testing set results can be concatenated afterwards, with each individual 
having been predicted by a model in which it was not trained. 


```{r function}

#Makes more sense to put it here than in a seperate file
instance_creation = function(dataset, printTest = F, nFoldsOuter = 8, nFoldsInner = 8){
    dataset = select(dataset, -drugname_typaslab)
    sampling_method = makeResampleDesc(method = "CV", iters = nFoldsOuter, stratify = TRUE)
    
    # outer instance
    outer_task =  makeClassifTask(data = dataset, target = "process_broad")
    sample_instance_outer =  makeResampleInstance(sampling_method, outer_task)
    
    if(printTest){
        # Testing stratification of outer instance
        for(i in 1:nFoldsOuter){
            cat("Fold", i, "- Train and test sets\n" )
            ind = sample_instance_outer$train.inds[[i]]
            print(table(dataset[ind, "process_broad"]))
            ind = sample_instance_outer$test.inds[[i]]
            print(table(dataset[ind, "process_broad"]))
        }
    }
    
    # defining inner instances
    sampling_method = makeResampleDesc(method = "CV", iters = nFoldsInner, stratify = TRUE)
    sample_instance_inner = list()
    for(i in 1:nFoldsOuter){
        inner_task = makeClassifTask(data = dataset[ sample_instance_outer$train.inds[[i]] , ], target = "process_broad")
        sample_instance_inner[[i]] = makeResampleInstance(sampling_method, inner_task)
    }
    
    if(printTest){
        # Testing stratification of inner instances
        # BE CAREFUL !!!
        # Indexes of individuals in the inner fold are the indexes of the vector of indexes of the corresponding outer fold 
        for (j in 1:nFoldsOuter ){
            outer_ind = sample_instance_outer$train.inds[[j]]
            cat("Outer fold", j, "\n")
            print(table(dataset[outer_ind, "process_broad"] ))
            cat("Inner folds \n")
            for (i in 1:nFoldsInner){
                ind = c(sample_instance_inner[[j]]$train.inds[[i]], sample_instance_inner[[j]]$test.inds[[i]])
                print(table(dataset[outer_ind[ind], "process_broad"]))
            }
        }
    }
    
    nested_CV_instance = list(outer = sample_instance_outer, inner = sample_instance_inner)
    return(nested_CV_instance)
}

```

## Creation of repeated CV instance - NEW LABELS

Creation of instances based on Nassos correction from 05/08/2018

```{r echo = F }

the_matrix_newDrugs = mutate(the_matrix_newDrugs, process_broad = replace(process_broad, process_broad %in% c("oxidative_stress", "pmf", "protein_qc"), "other"))

Rep_Nest_CV_instance_newDrugs = list()
dataset_newDrugs = filter(matrix_container, drug_dosages != "all") %>% select(drug_feature_matrices) %>% `[[`(1,1)
for(i in 1:10){
    name = paste("NCV_", as.character(i), sep="")
    Rep_Nest_CV_instance_newDrugs[[name]] = instance_creation(dataset = dataset_newDrugs, printTest = F)
}

```


# Testing chunks - print class repartition inside Folds

Just to be sure...The amount of each class in an inner set and the corresponding training set of the outer fold should be the same.

```{r eval = F}
#Test of outer folds, if they are all differents
a = list()
for (i in 1:10){
    a[[i]] = Rep_Nest_CV_instance[[i]]$outer$train.inds
}

a = unlist(a, recursive = F)

res = c()
for (i in 1:30){
    for(j in 1:30){
        if(i != j){
            res = c(res, length(unlist(setdiff(a[i], a[j]))) )
        }
    }
}

```



```{r export data}
save(Rep_Nest_CV_instance_newDrugs, file = "data/Rep_Nest_CV_instance_newDrugs.RData")

```


# System and session info

```{r}
R.Version
sessionInfo()
```
