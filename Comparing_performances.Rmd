---
title: "Comparing model performances"
author: "Florian Huber, Leonard Dubois"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

# Setup, library loading

This part is the general setup, whichever model we are using.

```{r setup}
# function to check if a package is installed, if so, load it, else install and then load it
source("./R/ipak.R")
# set chunk options and load libraries
source("./setup.R")
# custom functions
walk(list.files("./R", pattern = "*.R", full.names = T), source)
```

Modify some options for knitr. 

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 18, fig.height = 14)
theme_set(theme(text = element_text(size = 16)))
```


# Data preparation

## Reading in `run_results_from_server`

On the cluster, each of the rows of `matrix_container` was run; each row was a different combination 
of models, feature preselections etc and was saved in a separate results object 
(`./run_results_from_server/matrix_container_result`). Since the results objects are too big for 
putting them into `matrix_container` we will add new columns just containing the parts we are 
interested in. 

```{r reading_in, cache = TRUE, message = FALSE}
# old matrix_container object
load("./data/matrix_container.RData")
matrix_container_old <- matrix_container

##################################################
##### ROUTINE TO READ IN ALL RESULTS OBJECTS #####
##################################################

# What follows is a loop to extract information from our results objects and adding this into 
# new columns. Since this takes some time, it's written in a way that the matrix_container can be 
# updated. 

# results we already have
if (file.exists("./data/matrix_container_withextractions.rds")) {
   matrix_container <- readRDS("./data/matrix_container_withextractions.rds")
   matrix_container.bak <- matrix_container
   matrix_container <- matrix_container.bak
} else {
   matrix_container$hyperparam_grid_name <- names(matrix_container$hyperparam_grid)
   matrix_container$ThreshVsPerfData <- list(NA)
   matrix_container$PredData <- list(NA)
}

# available results files
available_files <- list.files("./run_results_from_server/matrix_container_result/", 
                              pattern = "xgboost|rf|lasso")
moas <- c("dna", "cell_wall", "protein_synthesis", "membrane_stress")

# loop to read in results files
for (rownum in seq_len(nrow(matrix_container))) {
   matrix_container_row <- matrix_container[rownum, ]
   # look for a file corresponding to a row
   targetfile <- paste(unlist(matrix_container_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_")
   targetfile <- paste0(targetfile, ".rds")
   my_match <- available_files[available_files == targetfile]
   
   # check if values are not defined: if yes: check if matching file exists or continue
   # if values are already defined means we parsed a corresponding results object previously so we 
   # can continue
   if ( any(is.na(unlist(matrix_container_row[, c("ThreshVsPerfData", "PredData")]))) ) {
      if (length(my_match) > 0) {
         cat("Match for unpopulated row ", rownum, "\t==>\t", my_match, "\n", sep = "")
      } else {
         cat("Didn't find a match for line ", rownum, ", continuing to next line.\n", sep = "")
         # warning("Didn't find a match for line ", rownum) # this doesn't work - no clue why - use cat()
         next
      }
   } else {
      # cat("Row ", rownum, " already populated, continuing to next line.\n")
      message("Row ", rownum, " already populated, continuing to next line.")
      next
   }
   
   resultsobj <- readRDS(paste0("./run_results_from_server/matrix_container_result/", my_match))
   
   # extract ThreshVsPerfData and prediction object data using some custom functions
   matrix_container$ThreshVsPerfData[[rownum]] <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = perf_extractor)
   
   # get prediction data, add drug name information and concentration
   pred_data <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = pred_extractor)
   pred_data$drugname_typaslab <- (matrix_container_row$drug_feature_matrices[[1]])$drugname_typaslab[pred_data$id]
   pred_data$conc <- (matrix_container_row$drug_feature_matrices[[1]])$conc[pred_data$id]
   matrix_container$PredData[[rownum]] <- pred_data
}

#  update
saveRDS(matrix_container, file = "./data/matrix_container_withextractions.rds")

# to get an example of a results object
my_row <- matrix_container[1, ]
(my_filename <- paste(unlist(my_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_"))
my_filename <- paste0("./run_results_from_server/matrix_container_result/", my_filename, ".rds")
stopifnot(file.exists(my_filename))
# example_res <- readRDS(my_filename)
rm(my_row, my_filename)
```



## Extracting results of the new matrix container

Similar to the one above but for the anlysis based on the matrix using 2 dosages by drug (most interactions)

```{r reading_in_new, eval = FALSE, message = FALSE}

matrix_container_new = readRDS("data/matrix_container_new.rds")

matrix_container_new$ThreshVsPerfData <- list(NA)
matrix_container_new$PredData <- list(NA)

# available results files
available_files <- list.files("./run_results_from_server/matrix_container_result/", 
                              pattern = "most2")
moas <- c("dna", "cell_wall", "protein_synthesis", "membrane_stress")

# loop to read in results files
for (rownum in seq_len(nrow(matrix_container_new))) {
   matrix_container_row <- matrix_container_new[rownum, ]
   # look for a file corresponding to a row
   targetfile <- paste(unlist(matrix_container_row[, c("drug_dosages", "fitted_model",  "feat_preselect", "chemical_feats")]), collapse = "_")
   targetfile <- paste0(targetfile, ".rds")
   my_match <- available_files[available_files == targetfile]
   
   # check if values are not defined: if yes: check if matching file exists or continue
   # if values are already defined means we parsed a corresponding results object previously so we 
   # can continue
   if ( any(is.na(unlist(matrix_container_row[, c("ThreshVsPerfData", "PredData")]))) ) {
      if (length(my_match) > 0) {
         message("Match for unpopulated row ", rownum, "\t==>\t", my_match, "\n", sep = "")
      } else {
         message("Didn't find a match for line ", rownum, ", continuing to next line.\n", sep = "")
         # warning("Didn't find a match for line ", rownum) # this doesn't work - no clue why - use cat()
         next
      }
   } else {
      message("Row ", rownum, " already populated, continuing to next line.\n")
      next
   }
   
   resultsobj <- readRDS(paste0("./run_results_from_server/matrix_container_result/", my_match))
   
   # extract ThreshVsPerfData and prediction object data using some custom functions
   matrix_container_new$ThreshVsPerfData[[rownum]] <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = perf_extractor)
   
   # get prediction data, add drug name information and concentration
   pred_data <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = pred_extractor)
   pred_data$drugname_typaslab <- (matrix_container_row$drug_feature_matrices[[1]])$drugname_typaslab[pred_data$id]
   pred_data$conc <- (matrix_container_row$drug_feature_matrices[[1]])$conc[pred_data$id]
   matrix_container_new$PredData[[rownum]] <- pred_data
}

#  update
saveRDS(matrix_container_new, file = "./data/matrix_container_new_withextractions.rds")

```


    

## Adding more information - `matrix_container_ext` & `stability_assessment`

Add information about MoA for each drug and which dosage is the dosage with most interactions. 
Replace all MoAs not being one of dna, membrane_stress, protein_synthesis, and cell_wall with 
"other". Results in object `matrix_container_ext`. 

```{r cache = TRUE, matrix_container_ext}
# remove NA rows
matrix_container_ext <- matrix_container[!is.na(matrix_container$PredData), ]

# we need a drug feature matrix for some of our annotations
drug_feature_matrix <- 
   filter(matrix_container, drug_dosages == "most_interactions", feat_preselect == "keepall", 
          chemical_feats == FALSE, fitted_model == "classif.randomForest") %>%
   pull(drug_feature_matrices) %>%
   map_dfr(identity)

stopifnot(nrow(drug_feature_matrix) < 100)

# add process_broad to each prediction data frame
matrix_container_ext$PredData <- 
   map2(matrix_container_ext$PredData, matrix_container_ext$drug_feature_matrices, function(.x, .y) {
      # get process_broad (moa) for each drug
      .x$process_broad <- .y$process_broad[.x$id] 
      return(.x)
   })

# beware! dosage with "most interactions" refers to the "keepall" features, as we can see here:
nrow(
   filter(matrix_container, drug_dosages == "most_interactions") %>%
   pull(drug_feature_matrices) %>%
   map_dfr(~ .x[, c("drugname_typaslab", "conc")]) %>%
   distinct()
)

# reference data frame from which we get the information which dosage has most interactions
most_interactions <- drug_feature_matrix[, c("drugname_typaslab", "conc")]

# add a column indicating which dosage is the one with most interactions
# also, replace moas not being "dna", "cell_wall", "membrane_stress", or "protein_synthesis" with "other"
matrix_container_ext$PredData <- 
   map(matrix_container_ext$PredData, function(.x) {
      # make vector indicating if the current concentration is the one with most interactions by temporary joining with our reference data frame
      conc_mostias <- 
         select(.x, drugname_typaslab, conc) %>%
         left_join(most_interactions, by = c("drugname_typaslab" = "drugname_typaslab"), suffix = c(".origin", ".mostias")) %>%
         mutate(conc.origin.is.mostias = (conc.origin == conc.mostias)) %>%
         pull(conc.origin.is.mostias)
      .x$conc_mostias <- conc_mostias
      .x$process_broad <- ifelse(.x$process_broad %in% c("dna", "cell_wall", "membrane_stress", "protein_synthesis"), 
                                 .x$process_broad, 
                                 "other")
      return(.x)
   })

# sanity check: is there just one concentration with most interactions per drug? 
# 40: because of 10 repeats and each drug being part of 4 models (one for each MoA)
stopifnot(length(unique(matrix_container_ext$PredData[[1]]$drugname_typaslab)) == sum(matrix_container_ext$PredData[[1]]$conc_mostias)/40)
```

For each model, each drug is predicted to have a certain probability to belong to each MoA. Since 
we did repeated nested CV, we can ask how stable these probabilities are. The same we can ask for 
auc measurements. To ask these questions, we make a table `stability_assessment`. We need a separate 
table to combine information for each repeat of the nested CV with unnesting to easily plot grouping 
variables. This table will also indicate whether `moa_modelled == moa_truth` or not as we want to 
compare stabilities of parameters depending on whether the drug actually belongs to the MoA we are 
trying to predict. We exclude all drugs with "other". 

```{r stability_assessment_table_I}
# write into a new table stability_assessment 
# here comes just an example of what this table will look like 
# these are the input data for *one* model
input_dat_exmpl <- matrix_container_ext$PredData[[1]]
head(input_dat_exmpl)

get_prob.moa_sds <- function(predDataTbl) {
   # take prediction data ("predDataTbl") and get for each drug the sd of the probabilities for which it is predicted 
   # to be a particular moa, once if moa_modelled == moa_actual and once moa_modelled != moa_actual 
   avg_sd_by_moa <- 
      predDataTbl %>%
      mutate(moa_modelled_is_truth = (moa_modelled == process_broad)) %>% # to distinguish the two cases 
      group_by(drugname_typaslab, moa_modelled_is_truth) %>% # we want to see stability for each drug depending on whether moa_modelled_is_truth 
      summarise(process_broad = unique(process_broad), 
                prob.moa_sd = sd(prob.moa), 
                prob.moa_sd2 = mean(tapply(prob.moa, conc, sd))) %>% # this is probably a better way to calculate the stability
      filter(process_broad != "other") # let's not consider these cases for now
   return(avg_sd_by_moa)
}

```

Here an example of what this looks like:

```{r stability_assessment_table_II}
get_prob.moa_sds(input_dat_exmpl)

# just to make sure it is correct (! we average over all dosages here)
get_prob.moa_sds(input_dat_exmpl)[2, "prob.moa_sd"]
# ... which should be equivalent to:
filter(input_dat_exmpl, drugname_typaslab == "A22", moa_modelled == process_broad) %>%
   pull(prob.moa) %>%
   sd()

## and now apply this to each model:
stability_assessment <- 
   matrix_container_ext %>% 
   select(drug_dosages, feat_preselect, chemical_feats, fitted_model, hyperparam_grid_name, PredData) %>%
   mutate(prob.moa_stabilities = map(PredData, get_prob.moa_sds))


## do the same thing now for aucs
# again, here is an example:
get_aucs_per_repeat <- function(predDataTbl) {
   #### TO DO: extract concatenated results objects already at the beginning, then they can be coerced to ROCR objects to get partial AUCs
   # take threshVsPerfData (= argument predDataTbl) and calculate auc for each repeat and each moa
   aucs <- 
      predDataTbl %>%
      mutate(negative = paste0("not_", moa_modelled)) %>%
      group_by(cvrep, moa_modelled) %>% # => we don't get aucs per fold but for the concatenation of all folds per repeat per moa
      summarise(auc = measureAUC(probabilities = prob.moa, truth = truth, negative = negative, positive = moa_modelled)) %>% 
      ungroup()
   return(aucs)
}

# example output
get_aucs_per_repeat(input_dat_exmpl)

# and apply again to each model
stability_assessment$auc_stabilities <- map(stability_assessment$PredData, get_aucs_per_repeat)
```

Re-read results objects so we can get partial AUCs (with a cutoff of e.g. fpr = 0.1). 

```{r message = FALSE, stability_assessment_tableIII_partialAUCs}

# results we already have
if (file.exists("./data/stability_assessment.rds")) {
   stability_assessment <- readRDS("./data/stability_assessment.rds")
} else {
   stability_assessment$auc_stabilities_new <- list(NA)
}

# available results files
available_files <- list.files("./run_results_from_server/matrix_container_result/", 
                              pattern = "xgboost|rf|lasso")
moas <- c("dna", "cell_wall", "protein_synthesis", "membrane_stress")

# like above - might write a function for this at some point

for (rownum in seq_len(nrow(stability_assessment))) {
   stability_assessment_row <- stability_assessment[rownum, ]
   # look for a file corresponding to a row
   targetfile <- paste(unlist(stability_assessment_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_")
   targetfile <- paste0(targetfile, ".rds")
   my_match <- available_files[available_files == targetfile]
   
   # check if values are not defined: if yes: check if matching file exists or continue
   # if values are already defined means we parsed a corresponding results object previously so we 
   # can continue
   if ( any(is.na(stability_assessment_row$auc_stabilities_new[[1]])) ){ # [, c("auc_stabilities_new")]))) ) {
      if (length(my_match) > 0) {
         message("Match for unpopulated row ", rownum, "\t==>\t", my_match, "\n", sep = "")
      } else {
         message("Didn't find a match for line ", rownum, ", continuing to next line.\n", sep = "")
         next
      }
   } else {
      message("Row ", rownum, " already populated, continuing to next line.\n")
      next
   }
   
   resultsobj <- readRDS(paste0("./run_results_from_server/matrix_container_result/", my_match))
   
   my_dfr <- expand.grid(cvrep = names(resultsobj), 
                         moa_modelled = c("cell_wall", "dna", "membrane_stress", "protein_synthesis"), 
                         stringsAsFactors = FALSE)
   my_dfr <- as_tibble(my_dfr)
   
   # get one prediction object per repetition of the nested CV per mode of action
   # concatenate the prediction object data slots
   my_dfr$predobj <- 
      map2(my_dfr$cvrep, my_dfr$moa_modelled, function(.cvrep, .moa) {
         # we don't want a separate AUC for each outer fold but we need the structure of the 
         # results object to concatenate the results of the other folds (this works correctly, 
         # I checked)
         pred_obj_shell <- resultsobj[[.cvrep]][["Outer fold 1"]][[paste0("prediction_", .moa)]] 
         pred_obj_shell$data <- map_dfr(resultsobj[[.cvrep]], function(.x) {
            return(.x[[paste0("prediction_", .moa)]]$data) # fetch the data slot for each fold of a specific .cvrep
         })
         return(pred_obj_shell)
      })
   my_dfr$auc <- map_dbl(my_dfr$predobj, ~ ROCR::performance(mlr::asROCRPrediction(.x), measure = "auc")@y.values[[1]]) # accessory functions for ROCR???
   my_dfr$part_auc_01 <- map_dbl(my_dfr$predobj, ~ ROCR::performance(mlr::asROCRPrediction(.x), measure = "auc", fpr.stop = 0.1)@y.values[[1]])
   
   stability_assessment$auc_stabilities_new[[rownum]] <- my_dfr
   rm(resultsobj)
}

#  update
saveRDS(stability_assessment, file = "./data/stability_assessment.rds")

# ggplot(my_dfr, aes(x = auc, y = part_auc_01)) + 
#    geom_point(aes(colour = moa_modelled)) + 
#    geom_smooth(aes(colour = moa_modelled), method = "lm")

# for ordering in plots further downstream
stability_assessment$feat_preselect <- 
   factor(stability_assessment$feat_preselect, 
          levels =  c("top5pct", "top10pct", "top15pct", "top20pct", "top25pct", "top30pct", 
                      "top40pct", "top50pct", "keepall"))
```



# Data analysis

## Model performances: comparing AUCs

Which models have the best AUCs and how does it change between models, feature_preselections and so 
on. Also allows assessing how stable AUCs are across repetitions of nested CV. 

### AUCs: impact of feat_preselect 

Without chemical features, using most_interactions. "keepall" corresponds to 1712 features.

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa <- function(dataset, xaxis, yaxis, colourvar, 
                            facet_expr = quote(facet_grid(fitted_model ~ .)), 
                            additional_info, showPlot = TRUE) {
   p <- 
      ggplot(dataset, aes_string(x = xaxis, y = yaxis, colour = colourvar)) + 
      geom_boxplot(position = position_dodge(), outlier.shape = NA) + 
      geom_point(position = position_jitterdodge(jitter.width = 0.1), size = 1, alpha = 0.5) + 
      eval(facet_expr) + 
      labs(x = "Mode of action modelled", y = paste0(yaxis, "(one dot per repeat of nested CV)"), 
           title = paste0("Performances of MoA predictions\n", additional_info)) + 
      theme_bw() + 
      theme(axis.text.x = element_text(angle = 45, hjust = 1), text = element_text(size = 18))
   
   if (showPlot) print(p)
   invisible(p)
}

plot_auc_vs_moa(foo, xaxis = "moa_modelled", y = "auc", colourvar = "feat_preselect", 
                additional_info = "(no chem. feats, most_interactions)")
# sanity check - just to show that aucs vom results objects are the same 
# note the 1 suffix
# plot_auc_vs_moa(foo, xaxis = "moa_modelled1", y = "auc1", colourvar = "feat_preselect", 
#                 additional_info = "(no chem. feats, most_interactions)")

# ggsave(plot = p, filename = "./plots/AUC_stabilities_mostinteractions.pdf", width = 16)
```

Conclusions: it depends on the MoA:

- `cell_wall` performs best overall and is relatively stable. top15pct seems to be better for RF 
whereas top5pct is best for lasso. For lasso performance seems to drop slightly with the higher number of 
features that are kept. 
- `dna` also has a decent performance (a bit better for RF) which is again quite stable. For lasso again the performance 
seems to drop slightly with the increasing number of features. But perhaps it also just reflects the 
instability of the lasso model as performance goes up again later on. 
- `membrane_stress` has overall the worst performance and is also the least stable. 
- `protein_synthesis` performs poorly for RF and lasso with top5 and top10pct but performance goes 
up with top15pct (RF) and top20pct (lasso), respectively. 

When looking closely: cell_wall and dna are a bit more stable with RF. 

But how does this compare to partial AUCs (fpr.stop = 0.1)? Note that for this threshold random 
chance is a partial auc of `r round((0.1^2) / 2, digits = 3)`. 

```{r}
plot_auc_vs_moa(foo, xaxis = "moa_modelled1", y = "part_auc_01", colourvar = "feat_preselect", 
                additional_info = "(no chem. feats, most_interactions)")
```

The trends are the same for cell_wall and dna. For protein synthesis, it seems more clear that more 
features = better - take at least top20pct. Membrane_stress performs poorly and partial AUCs suggest 
that some of the curves do not perform better than chance at a low fpr cutoff. 

XGBOOST models don't seem to bring a particular performance benefit. As they vary a lot depending 
on the hyperparameter grid but are difficult to understand I'd rather prefer lasso/RF models. 


### AUCs: all dosages vs. most_interactions

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE) %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "auc", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled)), 
                additional_info = "(no chem. feats)")

# ggsave(plot = p, filename = "./plots/AUC_stabilities_alldosages_vs_mostinteractions.pdf", width = 16, height = 10)
```

Conclusions: RF: most_interactions performs a bit better for cell_wall and dna, all dosages 
clearly improves performances for membrane_stress and, for lower feature numbers, protein_synthesis. 
Similar trend for lasso and membrane_stress/protein_synthesis. For lasso and dna/cell_wall it's less 
uniform, all dosages performs better for cell_wall and high feature numbers. 

Let's check again for partial AUCs:

```{r}
plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(no chem. feats)")
```

Trends in favour of all dosages are even clearer. cell_wall and RF has an inverted trend with all 
dosages now performing better. Overall, performance measures argue for using all dosages. 


There doesn't seem to be a big difference. 


### AUCs: with and without chemical features

```{r}
foo <- 
   stability_assessment %>%
   filter(drug_dosages == "all") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "auc", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled)), 
                additional_info = "(all dosages)")

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(all dosages)")

# ggsave(plot = p, filename = "./plots/AUC_stabilities_plusminus_chemical_feats.pdf", width = 16, height = 10)
```

Conclusions: chemical features bring big improvement in performance for protein_synthesis and, 
for occasional repeats, for membrane_stress. Interestingly, when choosing "most_interactions", the 
performance improvement for protein_synthesis is only there for low feature numbers:

```{r}
foo <- 
   stability_assessment %>%
   filter(drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "auc", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled)), 
                additional_info = "(most interactions)")

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(most interactions)")
```

With partial AUCs.

```{r}
plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(most interactions)")
```


But caution: physicochemical features may not be truly predictive - compare file 
drug_drug_similarities_RDKit.pdf. 

From the plots above we would probably say: take all dosages, with chemical features, top20pct, 
slight preference for RF. 


## Model stabilities 

Stability here means: how much do prediction probabilities fluctuate for drugs across different ways 
of splitting the data (i.e. each repetition of the nested CV). 


## 'Ultimate plot'

Shows the distribution of probabilities for each drug across repeats of the nested CV. Can plot 
only one model at a time. Grey rectangles indicate the dosage with the most interactions. 

```{r, ultimate_plots}
# Let's start with 2 ultimate plots for now: random forests, keepall, no chemical features, all dosages
# (what we discussed with Nassos)
# other stuff to come later
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.randomForest", drug_dosages == "all")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_alldosages_nochemfeats.pdf")

# let's try also for one of the lasso models
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.glmnet", drug_dosages == "all")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_alldosages_nochemfeats.pdf")

# and now both of them with just the "most_interactions" dosage
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.randomForest", drug_dosages == "most_interactions")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_mostinteractions_nochemfeats.pdf")


tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.glmnet", drug_dosages == "most_interactions")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_mostinteractions_nochemfeats.pdf")
```


## Stabilities of probabilities: global comparison

Calculate the standard deviation of the probabilities assigned to each drug for each mode of action. 
Different dosages will be lumped together. 


### Stabilities of probabilities: impact of feat_preselect

Fixing the following:

- chemical_feats == FALSE
- drug_dosages == "most_interactions"
- moa_modelled == truth

What is the impact of feat_preselect on model stability, depending on the model type and the 
hyperparameter grid?

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest() %>%
   filter(moa_modelled_is_truth)
head(foo)

plot_auc_vs_moa(foo, xaxis = "process_broad", yaxis = "prob.moa_sd2", colourvar = "feat_preselect", 
                facet_expr = quote(facet_grid(fitted_model ~ .)), 
                additional_info = "no chem. feats, most_interactions, MoA modelled = MoA truth")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_by_feat_preselect.pdf", width = 10, height = 7)


# What about 'classif.xgboost'? - Possible that stabilities depend on hyperparameter grid?
foo <- foo[foo$fitted_model == "classif.xgboost", ]
plot_auc_vs_moa(foo, xaxis = "process_broad", yaxis = "prob.moa_sd", colourvar = "feat_preselect", 
                facet_expr = quote(facet_grid(hyperparam_grid_name ~ .)), 
                additional_info = "classif.xgboost only\nno chem. feats, most_interactions, MoA modelled = MoA truth")

#ggsave(plot = p, filename = "./plots/Prob_stabilities_by_feat_preselect_onlyxgboost.pdf")
```

Conclusion: No apparent correlation between feat_preselect and stabilities of probabilities. 
Random forests is the most stable model, lasso the least stable one although the latter 
has a big difference between individual drugs: some of them are as stable as with RF. These trends 
are also apparent in the ultimate plot. 

Boosted trees is in between. For boosted trees the don't seem to differ between different 
hyperparameter grids. 


### Stabilities of probabilities: impact of all dosages vs. most_interactions

Just like above, except that we now want to see whether models become more or less stable if all 
dosages are used or only one dosage with most interactions. 

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE) %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest() %>%
   filter(moa_modelled_is_truth)
# head(foo)

plot_auc_vs_moa(foo, xaxis = "feat_preselect", yaxis = "prob.moa_sd2", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(fitted_model ~ process_broad)), 
                additional_info = "no chem. feats, MoA modelled = MoA truth")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_all_vs_mostinteractions.pdf", width = 16)

# focus again only on classif.xgboost
foo <- foo[foo$fitted_model == "classif.xgboost", ]

plot_auc_vs_moa(foo, xaxis = "process_broad", yaxis = "prob.moa_sd2", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(hyperparam_grid_name ~ feat_preselect)), 
                additional_info = "no chem. feats, MoA modelled = MoA truth")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_all_vs_mostinteractions_onlyxgboost.pdf", width = 16)
```

Conclusion: most interactions is a lot more stable for random forests and less so for boosted trees. 
For lasso there is also a trend to be more stable with most interactions but the data are very noisy 
and it depends a bit on the mode of action. 

Interestingly: stabilities change a bit between MoAs/feature sets for random forests but only if all 
dosages are used, not if just most_interactions are used, which would be another argument for using 
just one dosage. 

Why are stabilities quite different between MoAs between the MoAs, especially for lasso? Why are 
most_interactions a lot more stable for RF but only a bit more stable for lasso? Can we conclude 
anything from the stability differences between MoAs for the lasso or is this just the normal noise 
of the model?


### Stabilities of probabilities: impact of whether MoA modelled = truth

Like above but this time we do not focus on the probabilities where the MoA that was being modelled 
is the same as the MoA of the drug. So we ask whether drugs are more stably predicted to be their 
MoA or whether they are more stably predicted to be not their MoA. Check once for all dosages and 
once for most_interactions. 

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", yaxis = "prob.moa_sd2", 
                colourvar = "moa_modelled_is_truth", 
                facet_expr = quote(facet_grid(fitted_model ~ process_broad)), 
                additional_info = "(no chem. feats, most_interactions)")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_moa_modelled_is_truth_mostinteractions.pdf", width = 16)

foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "all") %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", yaxis = "prob.moa_sd2", 
                colourvar = "moa_modelled_is_truth", 
                facet_expr = quote(facet_grid(fitted_model ~ process_broad)), 
                additional_info = "(no chem. feats, all dosages)")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_moa_modelled_is_truth_alldosages.pdf", width = 16)
```

Conclusion: predictions where drug MoA == MoA modelled are more stable except for lasso where it's 
vice versa. Interestingly, with all dosages, predictions where MoA == moa_modelled get a lot more 
unstable for RF. 


<!--
TO DO:
- investigate dosage question: correlation (see below), distribution between drugs; note that chemical features wouldn't be necessary with most_interactions
- discuss issue with chemical features: correlations, naive KNN model, literature
- check selected ROC and precision-recall curves
- continue below, look at matrix_container_new
-->

## Further investigations on drug dosages

It looks like using all dosages is better than most_interactions. At the same time, it seems 
plausible that some dosages will be "wrong" in terms of having a too low drug dosages. Moreover, 
some drugs were tested with only 1 dosage, others with 6, which would lead to an overweighting of 
the latter drugs. Perhaps there is a compromise such as using the 2 dosages with most interactions? 
Also, it'd be interesting to see if there is a correlation of the number of interactions and 
prediction probabilities. 


### Correlating the number of significant interactions per drug with prediction probabilities

From the ultimate plot it seems like the dosages with the most interactions are also often the ones 
that are best at predicting a particular MoA. However, this is not always the case. Moreover, we 
don't know how many interactions this actually corresponds to. In addition, one may wonder whether 
some poorly predicted drugs are poorly predicted because they show only very few interactions even 
with "most_interactions". 


#### Preparing the data

This is a bit tricky because we need to get `the_matrix` from the first notebook ("1_DataLoading...") 
after the `do(select_mutant(.))` step. In addition, the number of significant interactions will 
depend on the number of features that have been preselected. 

```{r, eval = FALSE}
the_matrix <- readRDS("./data/the_matrix_after_select_mutant.rds")

get_nsignif <- function(drugfeatmat, predDataTbl, the_matrix) {
   # drugfeatmat: from matrix_container_ext: the drug_feature matrix
   # predDataTbl: from matrix_container_ext: the prediction table
   # the_matrix: from first notebook: the_matrix after the do(select_mutant(.)) step
   drugfeatmat_long <- select(drugfeatmat, -process_broad) %>% gather(3:ncol(.), key = "gene_synonym", value = "sscore")
   
   # by doing a join we can do a lookup which drug-concentration-gene combination is significant
   tab_nsignif <- left_join(drugfeatmat_long, the_matrix) %>%
      group_by(drugname_typaslab, conc) %>%
      summarise(n_signif = sum(significant, na.rm = TRUE))
   
   # and now join this back into the predDataTbl object - which is what we need for plotting
   tab_nsignif <- left_join(predDataTbl, tab_nsignif)
   tab_nsignif$moa_modelled_is_truth <- tab_nsignif$moa_modelled == tab_nsignif$process_broad
   
   # in this case we're not interested in the probabilities for each repeat of the nested CV, only 
   # in the median
   tab_nsignif <- tab_nsignif %>%
      group_by(drugname_typaslab, conc, moa_modelled, moa_modelled_is_truth, n_signif) %>%
      summarise(median_prob.moa = median(prob.moa))
   
   return(tab_nsignif)
}

# add a new list column to matrix_container_ext: similar to PredData but with median of prob.moa 
# and indicating how many significant interactions there are per drug and concentration using the 
# drug_feature_matrix that was used for that particular model 
matrix_container_ext$PredDataWithNSignif <- 
   map2(matrix_container_ext$drug_feature_matrices, matrix_container_ext$PredData, get_nsignif, the_matrix = the_matrix)
```

Now we can test how prediction probabilities compare with number of significant interactions. Take 
again RF, all dosages, no chemical features, keepall (same as ultimate plot above). 

```{r, eval = FALSE}
tmp <- filter(matrix_container_ext, fitted_model == "classif.randomForest", feat_preselect == "keepall", 
              chemical_feats == FALSE, drug_dosages == "all")
stopifnot(nrow(tmp) == 1)
tmp <- tmp$PredDataWithNSignif[[1]]

ggplot(tmp, aes(x = n_signif, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   facet_grid(moa_modelled ~ moa_modelled_is_truth) + 
   theme_bw() + 
   labs(x = "Number of significant interactions", y = "Median probability for MoA for each drug", 
        title = "Probabilities (y-axis) for MoA (right side) vs. number of sign. IAs (x-axis)\n
        (RF, all dosages, no chem feats, keepall)")

ggsave(filename = "./plots/Probabilities_vs_NSignif_RF_all_nochemfeats_keepall.pdf")

ggplot(tmp[tmp$moa_modelled == "cell_wall" & tmp$moa_modelled_is_truth, ], 
       aes(x = n_signif, y = median_prob.moa, colour = drugname_typaslab)) + 
   geom_point(shape = 1) + 
   geom_line(aes(group = drugname_typaslab)) + 
   geom_text(aes(label = drugname_typaslab), hjust = 0, nudge_x = 0.05) + 
   facet_grid(moa_modelled ~ moa_modelled_is_truth) + 
   theme_bw()

ggsave(filename = "./plots/Probabilities_vs_NSignif_cell_wall.pdf")
```




# Exploring matrix container - ROC curves 


```{r, eval = FALSE, echo = FALSE}

resMatrix = readRDS("/Volumes/typas/Florian/matrix_container_withextractions.rds")

plot_ROC_from_container(containerObj = resMatrix[1:18, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix[19:36, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix[37:54, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix[55:72, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "lasso_hyp_param"), moa = "all", by = c("feat_preselect", "drug_dosages"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "lasso_hyp_param"), moa = "all", by = c("feat_preselect", "drug_dosages"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "rf_hyp_param"), moa = "all", by = c("feat_preselect", "drug_dosages"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "xgboost_hyp_param_std"), moa = "all", by = c("feat_preselect", "drug_dosages"))


```

