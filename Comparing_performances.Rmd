---
title: "Comparing model performances"
author: "Florian Huber, Leonard Dubois"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

# Setup

```{r setup}
# set chunk options and load libraries, load custom functions
source("./setup.R")
resdir <- "./run_results_from_server/mc_2019"
outdir <- "./data/programmatic_output"

mc <- readRDS("./data/programmatic_output/mc.rds")
head(mics <- read_delim("./data/programmatic_output/MICs.csv", delim = ";"))
```


# Extracting information from nested CV runs 

```{r}
# old results object
# res_old <- readRDS("./run_results_from_server/matrix_container_result/rf_hyp_param_all_top10pct_FALSE.rds")
# pryr::object_size(res_old)

# new one
res_new <- readRDS(file.path(resdir, "classif.randomForest_one_FALSE.rds"))
pryr::object_size(res_new)
```

## Importing results from cluster

```{r}
mc_ext_old <- readRDS("./data/programmatic_output/matrix_container_ext_2019.rds")

mc_ext <- mc
mc_ext_path <- file.path(outdir, "mc_ext.rds")
newcols <- c("perf_measures", "pred_data", "opt_path", "opt_pars")
if (file.exists(mc_ext_path)) {
  mc_ext <- readRDS(mc_ext_path)
} else {
  mc_ext[, newcols] <- list(rep(list(NA), 4))
}

if (!file.exists(mc_ext_path)) {
  for (row in seq_len(nrow(mc_ext))) {
    gc()
    
    targetfile <- 
      select(mc_ext[row, ], fitted_model, drug_dosages, chemical_feats) %>%
      reduce(paste, sep = "_") %>% 
      paste0(".rds")
    
    stopifnot(length(targetfile) == 1)
    
    if (!(file.exists(file.path(resdir, targetfile)))) {
      cat(targetfile, ": no matching file found, continuing ...\n")
      next
    }
    
    cat("Now processing file ", targetfile, "\n")
    resobj <- readRDS(file.path(resdir, targetfile))
    
    mc_ext[row, newcols] <- 
      map(list(get_perf_measures_mcl, get_pred_data_mcl, get_opt_path, 
        get_opt_pars), function(f) list(f(resobj = resobj))) # need to wrap into list()
    
    rm(resobj)
    gc()
  }
}

saveRDS(mc_ext, file = mc_ext_path)
```

## Parsing results objects

```{r}
# model stabilities
mc_ext$pred_stabs <- map_if(mc_ext$pred_data, is_tibble, get_pred_stabs)

# adding additional information to pred_data
m_signif_all <- readRDS("./data/programmatic_output/m_signif_all.rds")
n_ias <- 
  m_signif_all %>%
  select(-one_of("drugname_typaslab", "conc", "process_broad")) %>% 
  apply(1, sum)

ia_stats <- bind_cols(
  m_signif_all[, c("drugname_typaslab", "conc", "process_broad")], 
  n_signif = n_ias)

ia_stats <- 
  group_by(ia_stats, drugname_typaslab) %>%
  mutate(conc_rank = rank(conc), n_conc = length(conc), 
    n_signif_rank = order(order(n_signif, conc)), 
    conc_mostias = which.max(n_signif) == seq_len(n()))

saveRDS(ia_stats, file = "./data/programmatic_output/ia_stats.rds")

# add additional info to pred data
mc_ext$pred_data <- map_if(mc_ext$pred_data, is_tibble, function(.x) {
  left_join(.x, select(ia_stats, -one_of("process_broad")))
})
```

# Comparison of models

## Performances

```{r}
# Most important plots: model performances, then model stabilities
# perhaps some total confusion matrix? 
plot_perf(mc_ext = mc_ext, what = "mmce_mean", save = TRUE, 
  file = "./plots/Comparison_performance_mmce.pdf")

plot_perf(mc_ext = mc_ext, what = "kappa_mean", save = TRUE, 
  file = "./plots/Comparison_performance_kappa.pdf")

## TO DO: IMPORTANT!
# number of preselected features, chemical features etc.: these parameters 
# should perhaps be plotted against the resulting performance (equivalent of 
# old plots where we had e.g. "impact of feature_preselect")
```

## Stabilities

```{r}
select(mc_ext, fitted_model, drug_dosages, chemical_feats, pred_stabs) %>%
  unnest() %>%
  ggplot(aes(x = fitted_model, y = sd_of_probs)) + 
  geom_violin() + 
    facet_grid(chemical_feats ~ drug_dosages) + 
  scale_x_discrete("Classifier type", labels = classifier_repl) + 
  comparison_theme + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggsave(filename = "./plots/Comparison_stabilities.pdf", width = 87, height = 80, 
  units = "mm")
```

# Define "winning" model

As the following plots are rather a quality control for the winning/chosen 
model. 

```{r}
# mc_ext_w = "winner", i.e. the model we choose
mc_ext_w <- filter(mc_ext, fitted_model == "classif.randomForest", 
  drug_dosages == "all", !chemical_feats)

pred_data_w <- mc_ext_w$pred_data[[1]]

resobj_w <- readRDS("./run_results_from_server/mc_2019/classif.randomForest_all_FALSE.rds")
```

## Performance of winning model

Confusion matrix

```{r}
# this code is similar to get_wide_confmat()
# sum up all confusion matrices
conf_mats <- map(resobj_w, function(ncv_rep) {
  conf_mats <- map(ncv_rep, function(fold) {
    calculateConfusionMatrix(fold$prediction, )$result
  })
  return(reduce(conf_mats, `+`))
})

cm_tot <- reduce(conf_mats, `+`)
cm_tot <- data.frame(cm_tot[-nrow(cm_tot), -ncol(cm_tot)], row.names = NULL, 
  stringsAsFactors = FALSE)

cm_tot$true <- colnames(cm_tot)
cm_tot <- gather(cm_tot, -one_of("true"), key = "predicted", value = "n_obs")

cm_tot$predicted <- factor(cm_tot$predicted)
cm_tot$true <- factor(cm_tot$true, levels = rev(levels(cm_tot$predicted)))

cm_tot$byclass_recall <- 
  cm_tot$n_obs / sapply(split(cm_tot$n_obs, cm_tot$true), sum)[cm_tot$true]

cm_tot$byclass_recall <- 
  cut(cm_tot$byclass_recall, breaks = seq(from = 0, to = 1, by = 0.1), 
    labels = c("0-10%", "10-20%", "20-30%", "30-40%", "40-50%", "50-60%", 
      "60-70%", "70-80%", "80-90%", "90-100%"))

cm_tot$byclass_recall[cm_tot$true != cm_tot$predicted] <- "0-10%"
#cm_tot$byclass_recall %<>% droplevels()

## ---------------
plot_wide_confmat(cm_tot, save = TRUE, file = "./plots/Confusion_matrix_chosen.pdf")
```


```{r}
le_plots <- map(moas, possibly(plot_roc_mcl, otherwise = NULL), 
  pred_data = pred_data_w)

pdf(file = "./plots/ROC_curves.pdf", width = 3.42, height = 2.76)
grid.arrange(le_plots[[1]], le_plots[[2]], le_plots[[3]], le_plots[[4]], ncol = 2)
dev.off()
```


## QC: Inner vs. outer performances

```{r}
plot_inner_vs_outer(mc_ext = mc_ext_w, save = TRUE, 
  file = "./plots/Comparison_inner-outer.pdf")
```

## QC: Stability of optimal hyperparameter values

```{r}
# stability of optimal hyperparameter values: do independently for each 
# model
# random forests:
tmp <- mc_ext_w %>%
  select(fitted_model, drug_dosages, chemical_feats, opt_pars) %>% 
  unnest() %>%
  mutate(opt_pars_value = map(opt_pars, unlist), opt_pars_name = map(opt_pars, names)) %>%
  unnest()

tmp$opt_pars_value %<>% factor(levels = sort(c(unique(tmp$opt_pars_value), 1.0)))

## TO DO: don't know how to show empty factor level with faceted plot when 
# setting scales = "free" - to show that the fw.perc = 1 value was kept
ggplot(tmp, aes(x = opt_pars_value)) + 
  geom_bar() + 
  facet_wrap( ~ opt_pars_name, scales = "free") + 
  comparison_theme

ggsave(filename = "./plots/Comparison_hyp-param_stabs.pdf", width = 87, 
  height = 95, units = "mm")

# prediction heatmap, pseudo ROC curves, confusion matrix
# general trends of prediction quality depending on hyperparameter chosen
```

## Prediction heatmap, prediction lines

```{r}
## TO DO: change order of y-axis
plot_mcl_probs_heatmap(melt_pred_data_mcl(pred_data_w), mics = mics, 
  printplot = FALSE, save = TRUE, file = "./plots/Pred_heatmap_training.pdf")

# NEW!
## TO DO: change to lollipop chart, see 
# https://www.r-bloggers.com/geom_lollipop-by-the-chartettes/
plot_mcl_probs_heatmap2(pred_data = pred_data_w, mics = mics, 
  printplot = TRUE, save = TRUE, order_by_conf = TRUE, 
  file = "./plots/Pred_heatmap_training_conf.pdf")

# profiles to see probabilities better
plot_mcl_probs_lines(melted_pred_data = melt_pred_data_mcl(pred_data_w), 
  save = TRUE, printplot = FALSE, file = "./plots/Pred_lines_training.pdf")
```

## QC: Calibration plot

```{r}
plot_prob_calib(pred_data = pred_data_w, save = TRUE, 
  file = "./plots/Probability_calibration.pdf")
```








<!-------------------------------------------------------------------------> 
<!-------------------------------------------------------------------------> 


Ignore the rest of the notebook for the time being, currently rewriting 
functions to accommodate multiclass models. 

```{r}
knitr::opts_chunk$set(eval = FALSE)
```


# Data analysis

## Model performances: comparing AUCs

### AUCs: impact of feat_preselect

### AUCs: all dosages vs. most_interactions

### AUCs: with and without chemical features

But caution: physicochemical features may not be truly predictive - compare file 
drug_drug_similarities_RDKit.pdf. 

## Model stabilities (of probabilities)

### 'Ultimate plot'

Shows the distribution of probabilities for each drug across repeats of the 
nested CV. Can plot only one model at a time. Grey rectangles indicate the 
dosage with the most interactions. 

```{r, ultimate_plots}
# tmp <- filter_container(matrix_container, feats = "keepall", chemfeats = FALSE, 
#   models = "classif.randomForest", dosgs = "all")
# 
# ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_alldosages_nochemfeats.pdf")
# 
# 
# # let's try also for one of the lasso models
# tmp <- filter_container(matrix_container, feats = "keepall", chemfeats = FALSE, 
#   models = "classif.glmnet", dosgs = "all")
# 
# ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_alldosages_nochemfeats.pdf")
# 
# 
# # and now both of them with just the "most_interactions" dosage
# tmp <- filter_container(matrix_container, feats = "keepall", chemfeats = FALSE, 
#   models = "classif.randomForest", dosgs = "most_interactions")
# 
# ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_mostinteractions_nochemfeats.pdf")
# 
# 
# tmp <- filter_container(matrix_container, feats = "keepall", chemfeats = FALSE, 
#   models = "classif.glmnet", dosgs = "most_interactions")
# 
# ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_mostinteractions_nochemfeats.pdf")
```


### Stabilities of probabilities: impact of feat_preselect


```{r, for_poster_again, echo = FALSE}
# # just for the poster
# foo <- 
#    matrix_container %>%
#    select(drug_dosages, feat_preselect, chemical_feats, fitted_model, prob.moa_stabilities) %>%
#    unnest() %>%
#    filter(fitted_model %in% c("classif.randomForest", "classif.glmnet"), 
#      moa_modelled_is_truth, drug_dosages == "all", !chemical_feats)
# 
# foo$process_broad <- 
#    fct_recode(foo$process_broad, 
#               "Cell Wall" = "cell_wall", 
#               "Protein Synthesis" = "protein_synthesis", 
#               "Membrane Stress" = "membrane_stress", 
#               "DNA" = "dna")
# 
# foo$fitted_model <- 
#    fct_recode(foo$fitted_model, 
#               "Random forests" = "classif.randomForest", 
#               "Lasso" = "classif.glmnet")
# 
# ggplot(foo, aes(x = feat_preselect, y = prob.moa_sd2, colour = drug_dosages)) + 
#    stat_summary(geom = "pointrange", group = "drug_dosages", fun.y = "median", fatten = 1, 
#                 fun.ymin = function(x) {fivenum(x)[2]}, 
#                 fun.ymax = function(x) {fivenum(x)[4]}) + 
#    stat_summary(geom = "line", fun.y = median, group = "drug_dosages") + 
#    facet_grid(fitted_model ~ process_broad) + 
#    labs(x = "Subset of features kept", y = "Median s.d. of prediction probability", 
#         title = "Stabilities of MoA prediction probabilities", 
#         subtitle = "Indicates s.d. of probabilities across nested CV repeats") + 
#    theme_bw() + 
#    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10), text = element_text(size = 14)) + 
#    scale_colour_manual("Drug concentrations", values = c("#1b9e77", "#d95f02"), 
#                        labels = c("All measured", "Conc. with \nmost interactions"))
# 
# ggsave("./plots/POSTER_stability_comp.pdf", width = 9, height = 5)
# 
# # GB seminar, version 2:
# 
# filter(foo, feat_preselect == "top15pct") %>%
#   ggplot(aes(x = fitted_model, y = prob.moa_sd2)) + 
#   geom_boxplot(notch = TRUE, outlier.shape = NA, width = 0.5) + 
#   geom_point(shape = 1, stroke = 1, alpha = 0.75, 
#     position = position_jitter(width = 0.15)) + 
#   labs(title = "Prediction variability between\ncross-validation repeats", 
#     x = "", y = "S.D. of predictions") + 
#   #scale_colour_manual("MoA", values = moa_cols, labels = names(moa_cols)) + 
#   theme(text = element_text(size = 14), panel.grid = element_blank())
# 
# ggsave("./plots/Stability_comparison_GBseminar.pdf", width = 3.8, height = 5)
# 
# # need a scheme for the prediction variabilities
# tmp <- filter_container(matrix_container, feats = "top15pct", chemfeats = FALSE, 
#   models = "classif.randomForest", dosgs = "all") %>%
#   pull(pred_data) %>%
#   `[[`(1) %>%
#   filter(drugname_typaslab == "TETRACYCLINE", conc == 1)
# 
# 
# 
# ggplot(tmp, aes(x = moa_modelled, y = prob.moa, colour = moa_modelled)) + 
#   geom_point(position = position_jitter(width = 0.15), size = 2, shape = 1, 
#     stroke = 1.2, alpha = 0.8) + 
#   labs(title = "Prediction probabilities for\ntetracycline", 
#     x = "Prediction for class", y = "Probability") + 
#   scale_x_discrete(labels = moa_repl) + 
#   scale_colour_manual(values = unname(moa_cols)) + 
#   theme(text = element_text(size = 14), axis.text.x = element_text(angle = 45, 
#     hjust = 1), panel.grid = element_blank(), legend.position = "None")
# 
# ggsave("./plots/Probabilities_tetracycline.pdf", width = 3.5, height = 5)
```


```{r, more_pretty_plots}
# foo <- filter_container(matrix_container, chemfeats = FALSE, 
#   models = "classif.randomForest") %>%
#   select(fitted_model, drug_dosages, feat_preselect, perf_measures) %>%
#   unnest() %>% 
#   filter(fitted_model == "classif.randomForest") %>% 
#   mutate(moa_modelled = fct_recode(moa_modelled, "Cell Wall" = "cell_wall", 
#     "Protein Synthesis" = "protein_synthesis", 
#     "Membrane Stress" = "membrane_stress", "DNA" = "dna"), 
#     moa_modelled = as.character(moa_modelled))
# 
# ggplot(filter(foo, moa_modelled == "Membrane Stress"), aes(x = feat_preselect, y = auc, colour = drug_dosages)) + 
#   stat_summary(geom = "line", fun.y = median, mapping = aes(group = drug_dosages)) + 
#   stat_summary(geom = "point", fun.y = median) + 
#   stat_summary(geom = "errorbar", fun.y = median, width = 0.2, alpha = 0.5, 
#     fun.ymin = function(x) {fivenum(x)[2]}, 
#     fun.ymax = function(x) {fivenum(x)[4]}) + 
#   geom_hline(yintercept = c(0.7, 0.75, 0.8), linetype = "dotted") + 
#   facet_wrap( ~ moa_modelled) + 
#   labs(x = "Subset of features kept", y = "Model performance [AUC]", 
#     title = "Impact of dosage and feature selection\non model performance") + 
#   theme_bw() + 
#   theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12), 
#     text = element_text(size = 14), panel.grid = element_blank()) + 
#   scale_colour_manual("Dosages kept", values = c("#1f78b4", "#33a02c"), 
#     labels = c("All", "Most interactions")) + 
#   NULL
# 
# ggsave("./plots/Perf_RF_all-vs-mostIAs_nochem_Membrane.pdf", width = 6, 
#   height = 4)
# 
# ggsave("./plots/Perf_RF_all-vs-mostIAs_nochem.pdf", width = 8, 
#   height = 6)
```


### Stabilities of probabilities: impact of all dosages vs. most_interactions


## Selected ROC/precision-recall curves

Random forests and lasso. 
Moreover, take with chemical features and using all dosages. Finally,
top20pct/keepall seemed to be decent feature preselections. So what do the ROC 
curves look like? 

```{r}
tmp <- filter(matrix_container, 
              fitted_model %in% c("classif.randomForest", "classif.glmnet"), 
              feat_preselect %in% c("top20pct", "keepall"), 
              drug_dosages == "all")

plot_perf_from_container(tmp[!tmp$chemical_feats, ], what = "ROC", 
  col_var = "feat_preselect", row_var = "fitted_model")

plot_perf_from_container(tmp[tmp$chemical_feats, ], what = "ROC", 
  col_var = "feat_preselect", row_var = "fitted_model")
```

Note: for cell_wall/dna/protein_synthesis: even though lasso and random forests 
are very similar for total AUCs (check top20pct), ROC curve shapes and, 
consequently, partial AUCs (see also above) show that random forests performs a 
lot better. Only for membrane_stress, lasso is the clear winner. 
But note the issue with probabilities, showing ROC curves for each repeat might 
still be useful. 

To be complete, here the precision-recall curves: 

```{r}
tmp <- tmp[!tmp$chemical_feats, ]

plot_perf_from_container(tmp, what = "prec-recall", col_var = "feat_preselect", 
  row_var = "fitted_model")
```


```{r, for_seminar}
foo <- filter(matrix_container, fitted_model == "classif.randomForest", 
  feat_preselect == "top15pct", drug_dosages == "all", !chemical_feats)

p <- plot_perf_from_container(foo, what = "ROC")
(p <- p + geom_vline(xintercept = 0.1, linetype = "dotted"))
ggsave("./plots/ROC_RF_top15pct_all_nochem.pdf", width = 7.5, height = 4)

plot_perf_from_container(foo, what = "prec-recall")
ggsave("./plots/Prec-recall_RF_top15pct_all_nochem.pdf", width = 5, height = 4.5)
```


## Further investigations on drug dosages

### Distributions of dosages among drugs

It looks like using all dosages is better than most_interactions. At the same 
time, it seems plausible that some dosages will be "wrong" in terms of having a 
too low drug dosage. Moreover, some drugs were tested with only 1 dosage, 
others with 6, which would lead to an overweighting of the latter drugs. 
Perhaps there is a compromise such as using the 2 dosages with most 
interactions? Also, it'd be interesting to see if there is a correlation of the 
number of interactions and prediction probabilities. 

How does number of dosages distribute among the different drugs and MoA?

```{r}
# take a drug_feature_matrix which has all dosages and all drugs etc. 
tmp <- readRDS("./data/programmatic_output/the_matrix_matrixcontainer_alldosg_2019.rds")
tmp <- select(tmp, drugname_typaslab, conc, process_broad) %>%
  group_by(drugname_typaslab, process_broad) %>%
  summarise(ndosages = n())

ggplot(tmp, aes(x = process_broad, y = ndosages, colour = process_broad)) + 
   ggbeeswarm::geom_beeswarm(groupOnX = TRUE, size = 2, cex = 1.5) + 
   theme_bw() + 
   theme(text = element_text(size = 18), axis.text.x = element_text(size = 18, 
     angle = 45, hjust = 1))

tapply(tmp$ndosages, tmp$process_broad, mean)
```


### Correlating the number of significant interactions per drug with prediction probabilities

From the ultimate plot it seems like the dosages with the most interactions 
might also be the ones that are best at predicting a particular MoA. However, 
the trend is not crystal clear. Moreover, we don't know how many interactions 
this actually corresponds to. In addition, one may wonder whether some poorly 
predicted drugs are poorly predicted because they show only very few 
interactions even with "most_interactions". 


#### Investigating number of interactions and class probabilities

General question: is there something like a minimum number of significant 
interactions to get useful predictions? 

```{r}
the_matrix <- readRDS("./data/programmatic_output/the_matrix_complete_strainsgenesremoved.rds")

tmp <- filter_container(matrix_container, models = "classif.randomForest", 
  feats = "top15pct", chemfeats = FALSE, dosgs = "all")

stopifnot(nrow(tmp) == 1)

tmp <- tmp$pred_data_with_n_signif[[1]] %>%
  filter(moa_modelled_is_truth) %>%
  mutate(moa_modelled = recode(moa_modelled, !!!moa_repl))

ggplot(tmp, aes(x = conc_rank, y = median_prob.moa, colour = moa_modelled)) + 
  geom_point(position = position_jitter(width = 0.15, height = 0), alpha = 0.8) + 
  theme_bw() + 
  facet_wrap( ~ moa_modelled) + 
  theme(text = element_text(size = 12)) + 
  labs(x = "Concentration rank", 
    y = "Median probability for MoA for each drug", 
    title = "Probabilities vs. number of interactions") + 
  scale_colour_manual("Target process", labels = names(moa_cols), 
    values = moa_cols)
  

ggsave("./plots/Probs_vs_conc.pdf", width = 6, height = 4.5)

group_by(tmp, moa_modelled) %>%
  summarise(rho = cor(x = n_signif, y = median_prob.moa, method = "spearman"), 
    pval = cor.test(x = n_signif, y = median_prob.moa, method = "spearman")$p.value)
```

But what about _within_ drugs? Do predictions profit from taking concentration 
with higher number of significant interactions? Exclude drugs with just one 
dosage. 

First check how n_signif ranks and conc_ranks correlate.

```{r}
# exclude cases where moa_modelled != truth and drugs with just one concentration
tmp2 <- tmp[tmp$moa_modelled_is_truth & tmp$n_conc > 1, ]

ggplot(tmp2, aes(x = conc_rank, y = n_signif_rank)) + 
   geom_count() + 
   labs(title = "Number of interactions vs. concentration", 
     subtitle = "Computed using ranks for each drug individually", 
     x = "Concentration rank", y = "Number of interactions rank")

cor.test(tmp2$conc_rank, tmp2$n_signif_rank, method = "spearman")

# novobiocin, for example:
filter(tmp2, drugname_typaslab == "NOVOBIOCIN")
```

Now compare prediction probabilities vs. ranks.

```{r}
ggplot(tmp2, aes(x = n_signif_rank, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   geom_line(aes(group = drugname_typaslab)) + 
   facet_grid(moa_modelled ~ n_conc) + 
   labs(title = "Median probability vs. concentration rank.\nEach line is a drug.")

ggplot(tmp2, aes(x = conc_rank, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   geom_line(aes(group = drugname_typaslab)) + 
   facet_grid(moa_modelled ~ n_conc) + 
   labs(title = "Median probability vs. n_signif interaction rank.\nEach line is a drug.")
```

It looks like it would actually be better to just take the two highest 
concentrations. This is also what a correlation test says:

```{r}
cor(x = tmp2$n_signif_rank, y = tmp2$median_prob.moa, method = "spearman")
cor(x = tmp2$conc_rank, y = tmp2$median_prob.moa, method = "spearman")
```

How do average probabilities change if we take the two dosages with most 
interactions/the two highest concentrations vs. the other 
dosages/concentrations? 

```{r}
tmp3 <- 
   tmp2 %>%
   group_by(moa_modelled, drugname_typaslab) %>%
   mutate(most2interactions = n_signif_rank %in% 
       sort(n_signif_rank, decreasing = TRUE)[1:2]) %>% 
   # split into 2 groups: two highest interactions and all lower dosages
   filter(n() > 2) %>% # keep only drugs where we can actually compare the effects
   group_by(drugname_typaslab, moa_modelled, most2interactions) %>% # summarise within those groups
   summarise(mean.median_prob.moa = mean(median_prob.moa)) %>%
   ungroup()

ggplot(tmp3, aes(x = most2interactions, y = mean.median_prob.moa, 
  colour = most2interactions)) + 
   geom_boxplot() + 
   geom_point() +
   geom_line(aes(group = drugname_typaslab), colour = "black") + 
   facet_wrap( ~ moa_modelled)

tmp3
kruskal <- lapply(split(tmp3, tmp3$moa_modelled), function(x) {
  x <- split(x$mean.median_prob.moa, x$most2interactions)
  })
lapply(kruskal, kruskal.test)
```

Another argument against using all dosages is that it leads to a higher degree 
of correlation of the features between the observations: within dosage 
correlation is significantly higher than between dosage correlation (see 
notebook "Misc.Rmd") so our degree of dependency between observations is likely 
to drop. 


## Further investigations on chemical features

First thing to note is that there is a considerable correlation between the 
chemical featues we use for the drugs in our data set. High correlation between 
features is problematic for a number of reasons: first, they indicate redundant 
information. Second, it can lead to model instability (cf. pages 12, 46 in 
Kuhn & Johnson, 2013). 

To show how strongly the chemical features are correlated:

```{r, eval = FALSE}
tmp <- matrix_container[180, ]
stopifnot(nrow(tmp) == 1 & tmp$drug_dosages == "most_interactions" & tmp$chemical_feats)
tmp <- tmp$drug_feature_matrices[[1]]

# we have 13 chemical features
tmp_m <- select(tmp, (ncol(tmp) - 12):ncol(tmp))
tmp_m <- as.matrix(tmp_m)
row.names(tmp_m) <- tmp$drugname_typaslab
tmp_m_cor <- cor(tmp_m)

corrplot::corrplot(tmp_m_cor, method = "color", order = "hclust", tl.cex = 0.7)
corrplot::corrplot(tmp_m_cor, type = "upper", method = "number", order = "hclust", tl.cex = 0.4)
```

As can also be seen in the plot "drug_drug_similarities_RDKit.pdf" (notebook 
Misc) some of our chemical features are biased towards distinguishing 
protein_synthesis from the other features. However, number of amide bonds 
favours cell wall, number of aromatic rings might favour DNA. 

```{r, eval = FALSE}
select(tmp, drugname_typaslab, process_broad, (ncol(tmp) - 12):ncol(tmp)) %>%
   filter(process_broad %in% c("cell_wall", "dna", "protein_synthesis", "membrane_stress")) %>%
   gather(-drugname_typaslab, -process_broad, key = "chemical_feature", value = "value") %>%
   ggplot(aes(x = process_broad, y = value, colour = process_broad)) + 
      ggbeeswarm::geom_beeswarm(groupOnX = TRUE, cex = 2, shape = 1) + 
      facet_wrap( ~ chemical_feature, ncol = 5, scales = "free_y") + 
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
      labs(title = "Distribution of chemical features across MoAs")
```

Check which drugs have high number of aliphatic rings and of saturated rings. This seems to bias 
the models using chemical features towards protein synthesis. 

```{r, eval = FALSE}
tmp$drugname_typaslab[tmp$NumAliphaticRings > 2.5]
tmp$drugname_typaslab[tmp$NumSaturatedRings > 2.5]
```


# System and session info

```{r, session_info}
R.version
sessionInfo()
```
