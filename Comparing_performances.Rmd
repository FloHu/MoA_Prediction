---
title: "Comparing model performances"
author: "Florian Huber, Leonard Dubois"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

# Setup, library loading

This part is the general setup, whichever model we are using.

```{r setup}
# function to check if a package is installed, if so, load it, else install and then load it
source("./R/ipak.R")
# set chunk options and load libraries
source("./setup.R")
# custom functions
walk(list.files("./R", pattern = "*.R", full.names = T), source)
```

Modify some options for knitr. 

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 18, fig.height = 14, cache = TRUE)
theme_set(theme_bw())
theme_update(text = element_text(size = 16))
```


# Data preparation

## Reading in `run_results_from_server`

On the cluster, each of the rows of `matrix_container` was run; each row was a different combination 
of models, feature preselections etc and was saved in a separate results object 
(`./run_results_from_server/matrix_container_result`). Since the results objects are too big for 
putting them into `matrix_container` we will add new columns just containing the parts we are 
interested in. 

```{r reading_in, message = FALSE}
# old matrix_container object
load("./data/matrix_container.RData")
matrix_container_old <- matrix_container

##################################################
##### ROUTINE TO READ IN ALL RESULTS OBJECTS #####
##################################################

# What follows is a loop to extract information from our results objects and adding this into 
# new columns. Since this takes some time, it's written in a way that the matrix_container can be 
# updated. 

# results we already have
if (file.exists("./data/matrix_container_withextractions.rds")) {
   matrix_container <- readRDS("./data/matrix_container_withextractions.rds")
   matrix_container.bak <- matrix_container
   matrix_container <- matrix_container.bak
} else {
   matrix_container$hyperparam_grid_name <- names(matrix_container$hyperparam_grid)
   matrix_container$ThreshVsPerfData <- list(NA)
   matrix_container$PredData <- list(NA)
}

# available results files
available_files <- list.files("./run_results_from_server/matrix_container_result/", 
                              pattern = "xgboost|rf|lasso")
moas <- c("dna", "cell_wall", "protein_synthesis", "membrane_stress")

# loop to read in results files
for (rownum in seq_len(nrow(matrix_container))) {
   matrix_container_row <- matrix_container[rownum, ]
   # look for a file corresponding to a row
   targetfile <- paste(unlist(matrix_container_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_")
   targetfile <- paste0(targetfile, ".rds")
   my_match <- available_files[available_files == targetfile]
   
   # check if values are not defined: if yes: check if matching file exists or continue
   # if values are already defined means we parsed a corresponding results object previously so we 
   # can continue
   if ( any(is.na(unlist(matrix_container_row[, c("ThreshVsPerfData", "PredData")]))) ) {
      if (length(my_match) > 0) {
         message("Match for unpopulated row ", rownum, "\t==>\t", my_match, sep = "")
      } else {
         message("Didn't find a match for line ", rownum, ", continuing to next line.", sep = "")
         # warning("Didn't find a match for line ", rownum) # this doesn't work - no clue why - use cat()
         next
      }
   } else {
      # cat("Row ", rownum, " already populated, continuing to next line.\n")
      message("Row ", rownum, " already populated, continuing to next line.")
      next
   }
   
   resultsobj <- readRDS(paste0("./run_results_from_server/matrix_container_result/", my_match))
   
   # extract ThreshVsPerfData and prediction object data using some custom functions
   matrix_container$ThreshVsPerfData[[rownum]] <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = perf_extractor)
   
   # get prediction data, add drug name information and concentration
   pred_data <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = pred_extractor)
   pred_data$drugname_typaslab <- (matrix_container_row$drug_feature_matrices[[1]])$drugname_typaslab[pred_data$id]
   pred_data$conc <- (matrix_container_row$drug_feature_matrices[[1]])$conc[pred_data$id]
   matrix_container$PredData[[rownum]] <- pred_data
}

# update
saveRDS(matrix_container, file = "./data/matrix_container_withextractions.rds")

# # to get an example of a results object
# my_row <- matrix_container[1, ]
# (my_filename <- paste(unlist(my_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_"))
# my_filename <- paste0("./run_results_from_server/matrix_container_result/", my_filename, ".rds")
# stopifnot(file.exists(my_filename))
# # example_res <- readRDS(my_filename)
# rm(my_row, my_filename)
```



## Extracting results of the new matrix container

Similar to the one above but for the analysis based on the matrix using 2 dosages by drug (most 
interactions).

```{r reading_in_new, message = FALSE}
matrix_container_new = readRDS(file = "data/matrix_container_new.rds")

if (file.exists("./data/matrix_container_new_withextractions.rds")) {
   matrix_container_new <- readRDS("./data/matrix_container_new_withextractions.rds")
} else {
   matrix_container_new$hyperparam_grid_name <- names(matrix_container_new$hyperparam_grid)
   matrix_container_new$ThreshVsPerfData <- list(NA)
   matrix_container_new$PredData <- list(NA)
}

# available results files
available_files <- list.files("./run_results_from_server/matrix_container_result/", 
                              pattern = "most2")
moas <- c("dna", "cell_wall", "protein_synthesis", "membrane_stress")

# loop to read in results files
for (rownum in seq_len(nrow(matrix_container_new))) {
   matrix_container_row <- matrix_container_new[rownum, ]
   # look for a file corresponding to a row
   targetfile <- paste(unlist(matrix_container_row[, c("drug_dosages", "fitted_model",  "feat_preselect", "chemical_feats")]), collapse = "_")
   targetfile <- paste0(targetfile, ".rds")
   my_match <- available_files[available_files == targetfile]
   
   # check if values are not defined: if yes: check if matching file exists or continue
   # if values are already defined means we parsed a corresponding results object previously so we 
   # can continue
   if ( any(is.na(unlist(matrix_container_row[, c("ThreshVsPerfData", "PredData")]))) ) {
      if (length(my_match) > 0) {
         message("Match for unpopulated row ", rownum, "\t==>\t", my_match, sep = "")
      } else {
         message("Didn't find a match for line ", rownum, ", continuing to next line.", sep = "")
         # warning("Didn't find a match for line ", rownum) # this doesn't work - no clue why - use cat()
         next
      }
   } else {
      message("Row ", rownum, " already populated, continuing to next line.")
      next
   }
   
   resultsobj <- readRDS(paste0("./run_results_from_server/matrix_container_result/", my_match))
   
   # extract ThreshVsPerfData and prediction object data using some custom functions
   matrix_container_new$ThreshVsPerfData[[rownum]] <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = perf_extractor)
   
   # get prediction data, add drug name information and concentration
   pred_data <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = pred_extractor)
   pred_data$drugname_typaslab <- (matrix_container_row$drug_feature_matrices[[1]])$drugname_typaslab[pred_data$id]
   pred_data$conc <- (matrix_container_row$drug_feature_matrices[[1]])$conc[pred_data$id]
   matrix_container_new$PredData[[rownum]] <- pred_data
   rm(resultsobj)
   gc()
}

# update
saveRDS(matrix_container_new, file = "./data/matrix_container_new_withextractions.rds")
```


## Adding more information - `matrix_container_ext` & `stability_assessment`

Add information about MoA for each drug and which dosage is the dosage with most interactions. 
Replace all MoAs not being one of dna, membrane_stress, protein_synthesis, and cell_wall with 
"other". Results in object `matrix_container_ext`. 

```{r matrix_container_ext}
# remove NA rows
matrix_container_ext <- matrix_container[!is.na(matrix_container$PredData), ]

# we need a drug feature matrix for some of our annotations
drug_feature_matrix <- 
   filter(matrix_container, drug_dosages == "most_interactions", feat_preselect == "keepall", 
          chemical_feats == FALSE, fitted_model == "classif.randomForest") %>%
   pull(drug_feature_matrices) %>%
   map_dfr(identity)

stopifnot(nrow(drug_feature_matrix) < 100)

# add process_broad to each prediction data frame
matrix_container_ext$PredData <- 
   map2(matrix_container_ext$PredData, matrix_container_ext$drug_feature_matrices, function(.x, .y) {
      # get process_broad (moa) for each drug
      .x$process_broad <- .y$process_broad[.x$id] 
      return(.x)
   })

# beware! dosage with "most interactions" refers to the "keepall" features, as we can see here:
nrow(
   filter(matrix_container, drug_dosages == "most_interactions") %>%
   pull(drug_feature_matrices) %>%
   map_dfr(~ .x[, c("drugname_typaslab", "conc")]) %>%
   distinct()
)

# reference data frame from which we get the information which dosage has most interactions
most_interactions <- drug_feature_matrix[, c("drugname_typaslab", "conc")]

# add a column indicating which dosage is the one with most interactions
# also, replace moas not being "dna", "cell_wall", "membrane_stress", or "protein_synthesis" with "other"
matrix_container_ext$PredData <- 
   map(matrix_container_ext$PredData, function(.x) {
      # make vector indicating if the current concentration is the one with most interactions by 
      # temporary joining with our reference data frame
      conc_mostias <- 
         select(.x, drugname_typaslab, conc) %>%
         left_join(most_interactions, by = c("drugname_typaslab" = "drugname_typaslab"), 
                   suffix = c(".origin", ".mostias")) %>%
         mutate(conc.origin.is.mostias = (conc.origin == conc.mostias)) %>%
         pull(conc.origin.is.mostias)
      .x$conc_mostias <- conc_mostias
      .x$process_broad <- 
         ifelse(.x$process_broad %in% c("dna", "cell_wall", "membrane_stress", "protein_synthesis"), 
                .x$process_broad, 
                "other")
      return(.x)
   })

# sanity check: is there just one concentration with most interactions per drug? 
# 40: because of 10 repeats and each drug being part of 4 models (one for each MoA)
stopifnot(length(unique(matrix_container_ext$PredData[[1]]$drugname_typaslab)) == 
             sum(matrix_container_ext$PredData[[1]]$conc_mostias)/40)
```

For each model, each drug is predicted to have a certain probability to belong to each MoA. Since 
we did repeated nested CV, we can ask how stable these probabilities are. The same we can ask for 
auc measurements. To ask these questions, we make a table `stability_assessment`. We need a 
separate table to combine information for each repeat of the nested CV with unnesting to easily 
plot grouping variables. This table will also indicate whether `moa_modelled == moa_truth` or not 
as we want to compare stabilities of parameters depending on whether the drug actually belongs to 
the MoA we are trying to predict. We exclude all drugs with "other". 

```{r stability_assessment_table_I}
# write into a new table stability_assessment 
# here comes just an example of what this table will look like 
# these are the input data for *one* model
input_dat_exmpl <- matrix_container_ext$PredData[[1]]
head(input_dat_exmpl)

# an example of what we wanna have:
get_prob.moa_sds(input_dat_exmpl)

# just to make sure it is correct (! we average over all dosages here)
get_prob.moa_sds(input_dat_exmpl)[2, "prob.moa_sd"]
# ... which should be equivalent to:
filter(input_dat_exmpl, drugname_typaslab == "A22", moa_modelled == process_broad) %>%
   pull(prob.moa) %>%
   sd()

## and now apply this to each model:
stability_assessment <- 
   matrix_container_ext %>% 
   select(drug_dosages, feat_preselect, chemical_feats, fitted_model, hyperparam_grid_name, PredData) %>%
   mutate(prob.moa_stabilities = map(PredData, get_prob.moa_sds))

# do the same thing now for aucs
# again, here is an example:
get_aucs_per_repeat(input_dat_exmpl)

# and apply again to each model
stability_assessment$auc_stabilities <- map(stability_assessment$PredData, get_aucs_per_repeat)
```

Re-read results objects so we can get partial AUCs (with a cutoff of e.g. fpr = 0.1). 

```{r message = FALSE, stability_assessment_tableIII_partialAUCs}
# results we already have
if (file.exists("./data/stability_assessment.rds")) {
   stability_assessment <- readRDS("./data/stability_assessment.rds")
} else {
   stability_assessment$auc_stabilities_new <- list(NA)
}

# available results files
available_files <- list.files("./run_results_from_server/matrix_container_result/", 
                              pattern = "xgboost|rf|lasso")
moas <- c("dna", "cell_wall", "protein_synthesis", "membrane_stress")

# like above - might write a function for this at some point

for (rownum in seq_len(nrow(stability_assessment))) {
   stability_assessment_row <- stability_assessment[rownum, ]
   # look for a file corresponding to a row
   targetfile <- paste(unlist(stability_assessment_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_")
   # targetfile <- paste(unlist(stability_assessment_row[, c("drug_dosages", "fitted_model", "feat_preselect", "chemical_feats")]), collapse = "_")
   targetfile <- paste0(targetfile, ".rds")
   my_match <- available_files[available_files == targetfile]
   
   # check if values are not defined: if yes: check if matching file exists or continue
   # if values are already defined means we parsed a corresponding results object previously so we 
   # can continue
   if ( any(is.na(stability_assessment_row$auc_stabilities_new[[1]])) ){ # [, c("auc_stabilities_new")]))) ) {
      if (length(my_match) > 0) {
         message("Match for unpopulated row ", rownum, "\t==>\t", my_match, sep = "")
      } else {
         message("Didn't find a match for line ", rownum, ", continuing to next line.", sep = "")
         next
      }
   } else {
      message("Row ", rownum, " already populated, continuing to next line.")
      next
   }
   
   resultsobj <- readRDS(paste0("./run_results_from_server/matrix_container_result/", my_match))
   
   my_dfr <- expand.grid(cvrep = names(resultsobj), 
                         moa_modelled = c("cell_wall", "dna", "membrane_stress", "protein_synthesis"), 
                         stringsAsFactors = FALSE)
   my_dfr <- as_tibble(my_dfr)
   
   # get one prediction object per repetition of the nested CV per mode of action
   # concatenate the prediction object data slots
   my_dfr$predobj <- 
      map2(my_dfr$cvrep, my_dfr$moa_modelled, function(.cvrep, .moa) {
         # we don't want a separate AUC for each outer fold but we need the structure of the 
         # results object to concatenate the results of the other folds (this works correctly, 
         # I checked)
         pred_obj_shell <- resultsobj[[.cvrep]][["Outer fold 1"]][[paste0("prediction_", .moa)]] 
         pred_obj_shell$data <- map_dfr(resultsobj[[.cvrep]], function(.x) {
            return(.x[[paste0("prediction_", .moa)]]$data) # fetch the data slot for each fold of a specific .cvrep
         })
         return(pred_obj_shell)
      })
   my_dfr$auc <- map_dbl(my_dfr$predobj, ~ ROCR::performance(mlr::asROCRPrediction(.x), measure = "auc")@y.values[[1]]) # accessory functions for ROCR???
   my_dfr$part_auc_01 <- map_dbl(my_dfr$predobj, ~ ROCR::performance(mlr::asROCRPrediction(.x), measure = "auc", fpr.stop = 0.1)@y.values[[1]])
   
   stability_assessment$auc_stabilities_new[[rownum]] <- my_dfr
   rm(resultsobj)
}

# update
saveRDS(stability_assessment, file = "./data/stability_assessment.rds")

# for ordering in plots further downstream
stability_assessment$feat_preselect <- 
   factor(stability_assessment$feat_preselect, 
          levels =  c("top5pct", "top10pct", "top15pct", "top20pct", "top25pct", "top30pct", 
                      "top40pct", "top50pct", "keepall"))
```



# Data analysis

## Model performances: comparing AUCs

Which models have the best AUCs and how does it change between models, feature_preselections and so 
on. Also allows assessing how stable AUCs are across repetitions of nested CV. 

### AUCs: impact of feat_preselect 

Without chemical features, using most_interactions. "keepall" corresponds to 1712 features.

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "moa_modelled", y = "auc", colourvar = "feat_preselect", 
                additional_info = "(no chem. feats, most_interactions)")
# sanity check - just to show that aucs vom results objects are the same 
# note the 1 suffix
# plot_auc_vs_moa(foo, xaxis = "moa_modelled1", y = "auc1", colourvar = "feat_preselect", 
#                 additional_info = "(no chem. feats, most_interactions)")

# ggsave(filename = "./plots/AUC_stabilities_mostinteractions.pdf", width = 16)
```

Conclusions: it depends on the MoA:

- `cell_wall` performs best overall and is relatively stable. top15pct seems to be better for RF 
whereas top5pct is best for lasso. For lasso performance seems to drop slightly with the higher 
number of features that are kept. 
- `dna` also has a decent performance (a bit better for RF) which is again quite stable. For lasso 
again the performance seems to drop slightly with the increasing number of features. But perhaps 
it also just reflects the instability of the lasso model as performance goes up again later on. 
- `membrane_stress` has overall the worst performance and is also the least stable. 
- `protein_synthesis` performs poorly for RF and lasso with top5 and top10pct but performance goes 
up with top15pct (RF) and top20pct (lasso), respectively. 

When looking closely: cell_wall and dna are a bit more stable with RF. 

But how does this compare to partial AUCs (fpr.stop = 0.1)? Note that for this threshold random 
chance is a partial auc of `r round((0.1^2) / 2, digits = 3)`. 

```{r}
plot_auc_vs_moa(foo, xaxis = "moa_modelled1", y = "part_auc_01", colourvar = "feat_preselect", 
                additional_info = "(no chem. feats, most_interactions)")
```

The trends are the same for cell_wall and dna. For protein synthesis, it seems more clear that more 
features = better - take at least top20pct. Membrane_stress performs poorly and partial AUCs suggest 
that some of the curves do not perform better than chance at a low fpr cutoff. 

XGBOOST models don't seem to bring a particular performance benefit. As they vary a lot depending 
on the hyperparameter grid but are difficult to understand I'd rather prefer lasso/RF models. 


### AUCs: all dosages vs. most_interactions

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE) %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "auc", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled)), 
                additional_info = "(no chem. feats)")

# ggsave(plot = p, filename = "./plots/AUC_stabilities_alldosages_vs_mostinteractions.pdf", 
# width = 16, height = 10)
```


```{r, for_poster, echo = FALSE}
# this is just for the poster
foo <- 
   filter(foo, fitted_model %in% c("classif.randomForest", "classif.glmnet"))

foo$moa_modelled <- 
   fct_recode(foo$moa_modelled, 
              "Cell Wall" = "cell_wall", 
              "Protein Synthesis" = "protein_synthesis", 
              "Membrane Stress" = "membrane_stress", 
              "DNA" = "dna", 
              "Other" = "oxidative_stress", 
              "Other" = "pmf", 
              "Other" = "protein_qc")

foo$fitted_model <- 
   fct_recode(foo$fitted_model, 
              "Random forests" = "classif.randomForest", 
              "Lasso" = "classif.glmnet")

# foofilt <- filter(foo, fitted_model == "Lasso", moa_modelled == "DNA")
foo_by_repndosg <- 
   group_by(foo, fitted_model, moa_modelled, drug_dosages, feat_preselect) %>%
   summarise(median_auc = median(auc), 
             lower = boxplot.stats(auc)$stats[2], 
             upper = boxplot.stats(auc)$stats[4])
foo_by_repndosg

ggplot(foo, aes(x = feat_preselect, y = auc, colour = drug_dosages)) + 
   # geom_boxplot(position = position_dodge(), outlier.shape = NA) + 
   # geom_point(position = position_jitterdodge(jitter.width = 0.1), size = 1, alpha = 0.5) + 
   geom_pointrange(data = foo_by_repndosg, aes(y = median_auc, ymin = lower, ymax = upper), fatten = 1) + 
   geom_line(data = foo_by_repndosg, aes(y = median_auc, group = drug_dosages)) + 
   # stat_summary(geom = "line", group = "drug_dosages", fun.y = "median") + # this doesn't work, it will not draw separate line per drug_dosages - why?
   facet_grid(fitted_model ~ moa_modelled) + 
   labs(x = "Subset of features kept", y = "AUC", title = "Performances of MoA predictions", 
        subtitle = "Medians +- IQR across CV repeats indicated") + 
   theme_bw() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10), text = element_text(size = 14)) + 
   scale_colour_manual("Drug concentrations", values = c("#1b9e77", "#d95f02"), 
                       labels = c("All measured", "Conc. with \nmost interactions"))

ggsave("./plots/POSTER_performance_comp.pdf", width = 9, height = 5)
```

Conclusions: RF: most_interactions performs a bit better for cell_wall and dna, all dosages 
clearly improves performances for membrane_stress and, for lower feature numbers, protein_synthesis. 
Similar trend for lasso and membrane_stress/protein_synthesis. For lasso and dna/cell_wall it's less 
uniform, all dosages performs better for cell_wall and high feature numbers. 

Let's check again for partial AUCs:

```{r}
plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(no chem. feats)")
```

Trends in favour of all dosages are even clearer. cell_wall and RF has an inverted trend with all 
dosages now performing better. Overall, performance measures argue for using all dosages. 

There doesn't seem to be a big difference. 


### AUCs: with and without chemical features

```{r}
foo <- 
   stability_assessment %>%
   filter(drug_dosages == "all") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "auc", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled)), 
                additional_info = "(all dosages)")

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(all dosages)")

# ggsave(plot = p, filename = "./plots/AUC_stabilities_plusminus_chemical_feats.pdf", width = 16, 
# height = 10)
```

Conclusions: chemical features bring big improvement in performance for protein_synthesis and, 
for occasional repeats, for membrane_stress. Interestingly, when choosing "most_interactions", the 
performance improvement for protein_synthesis is only there for low feature numbers:

```{r}
foo <- 
   stability_assessment %>%
   filter(drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "auc", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled)), 
                additional_info = "(most interactions)")

plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(most interactions)")
```

With partial AUCs.

```{r}
plot_auc_vs_moa(foo, xaxis = "feat_preselect", y = "part_auc_01", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(fitted_model ~ moa_modelled1)), 
                additional_info = "(most interactions)")
```


But caution: physicochemical features may not be truly predictive - compare file 
drug_drug_similarities_RDKit.pdf. 

From the plots above we would probably say: take all dosages, with chemical features, top20pct/
top25pct, slight preference for RF. 


## Model stabilities (of probabilities)

Stability here means: how much do prediction probabilities fluctuate for drugs across different ways 
of splitting the data (i.e. each repetition of the nested CV). 


### 'Ultimate plot'

Shows the distribution of probabilities for each drug across repeats of the nested CV. Can plot 
only one model at a time. Grey rectangles indicate the dosage with the most interactions. 

```{r, ultimate_plots}
# Let's start with 2 ultimate plots for now: random forests, keepall, no chemical features, all dosages
# (what we discussed with Nassos)
# other stuff to come later
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.randomForest", drug_dosages == "all")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_alldosages_nochemfeats.pdf")

# let's try also for one of the lasso models
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.glmnet", drug_dosages == "all")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_alldosages_nochemfeats.pdf")

# and now both of them with just the "most_interactions" dosage
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.randomForest", drug_dosages == "most_interactions")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_mostinteractions_nochemfeats.pdf")


tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.glmnet", drug_dosages == "most_interactions")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_mostinteractions_nochemfeats.pdf")
```


### Stabilities of probabilities: impact of feat_preselect

Fixing the following:

- chemical_feats == FALSE
- drug_dosages == "most_interactions"
- moa_modelled == truth

What is the impact of feat_preselect on model stability, depending on the model type and the 
hyperparameter grid?

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest() %>%
   filter(moa_modelled_is_truth)
head(foo)

plot_auc_vs_moa(foo, xaxis = "process_broad", yaxis = "prob.moa_sd2", colourvar = "feat_preselect", 
                facet_expr = quote(facet_grid(fitted_model ~ .)), 
                additional_info = "no chem. feats, most_interactions, MoA modelled = MoA truth")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_by_feat_preselect.pdf", width = 10, height = 7)


# What about 'classif.xgboost'? - Possible that stabilities depend on hyperparameter grid?
foo <- foo[foo$fitted_model == "classif.xgboost", ]
plot_auc_vs_moa(foo, xaxis = "process_broad", yaxis = "prob.moa_sd", colourvar = "feat_preselect", 
                facet_expr = quote(facet_grid(hyperparam_grid_name ~ .)), 
                additional_info = "classif.xgboost only\nno chem. feats, most_interactions, MoA modelled = MoA truth")

#ggsave(plot = p, filename = "./plots/Prob_stabilities_by_feat_preselect_onlyxgboost.pdf")
```


```{r, for_poster_again, echo = FALSE}
# just for the poster
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE) %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest() %>%
   filter(fitted_model %in% c("classif.randomForest", "classif.glmnet"), moa_modelled_is_truth, 
          drug_dosages == "all")

foo$process_broad <- 
   fct_recode(foo$process_broad, 
              "Cell Wall" = "cell_wall", 
              "Protein Synthesis" = "protein_synthesis", 
              "Membrane Stress" = "membrane_stress", 
              "DNA" = "dna", 
              "Other" = "oxidative_stress", 
              "Other" = "pmf", 
              "Other" = "protein_qc")

foo$fitted_model <- 
   fct_recode(foo$fitted_model, 
              "Random forests" = "classif.randomForest", 
              "Lasso" = "classif.glmnet")

ggplot(foo, aes(x = feat_preselect, y = prob.moa_sd2, colour = drug_dosages)) + 
   stat_summary(geom = "pointrange", group = "drug_dosages", fun.y = "median", fatten = 1, 
                fun.ymin = function(x) {fivenum(x)[2]}, 
                fun.ymax = function(x) {fivenum(x)[4]}) + 
   stat_summary(geom = "line", fun.y = median, group = "drug_dosages") + 
   facet_grid(fitted_model ~ process_broad) + 
   labs(x = "Subset of features kept", y = "Median s.d. of prediction probability", 
        title = "Stabilities of MoA prediction probabilities", 
        subtitle = "Indicates s.d. of probabilities across nested CV repeats") + 
   theme_bw() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10), text = element_text(size = 14)) + 
   scale_colour_manual("Drug concentrations", values = c("#1b9e77", "#d95f02"), 
                       labels = c("All measured", "Conc. with \nmost interactions"))

ggsave("./plots/POSTER_stability_comp.pdf", width = 9, height = 5)

```


Conclusion: No apparent correlation between feat_preselect and stabilities of probabilities. 
Random forests is the most stable model, lasso the least stable one although the latter 
has a big difference between individual drugs: some of them are as stable as with RF. These trends 
are also apparent in the ultimate plot. 

Boosted trees is in between. For boosted trees the don't seem to differ between different 
hyperparameter grids. 


### Stabilities of probabilities: impact of all dosages vs. most_interactions

Just like above, except that we now want to see whether models become more or less stable if all 
dosages are used or only one dosage with most interactions. 

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE) %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest() %>%
   filter(moa_modelled_is_truth)
# head(foo)

plot_auc_vs_moa(foo, xaxis = "feat_preselect", yaxis = "prob.moa_sd2", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(fitted_model ~ process_broad)), 
                additional_info = "no chem. feats, MoA modelled = MoA truth")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_all_vs_mostinteractions.pdf", width = 16)

# focus again only on classif.xgboost
foo <- foo[foo$fitted_model == "classif.xgboost", ]

plot_auc_vs_moa(foo, xaxis = "process_broad", yaxis = "prob.moa_sd2", colourvar = "drug_dosages", 
                facet_expr = quote(facet_grid(hyperparam_grid_name ~ feat_preselect)), 
                additional_info = "no chem. feats, MoA modelled = MoA truth")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_all_vs_mostinteractions_onlyxgboost.pdf", width = 16)
```


### Stabilities of probabilities: impact of whether MoA modelled = truth

Like above but this time we do not focus on the probabilities where the MoA that was being modelled 
is the same as the MoA of the drug. So we ask whether drugs are more stably predicted to be their 
MoA or whether they are more stably predicted to be not their MoA. Check once for all dosages and 
once for most_interactions. 

```{r}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", yaxis = "prob.moa_sd2", 
                colourvar = "moa_modelled_is_truth", 
                facet_expr = quote(facet_grid(fitted_model ~ process_broad)), 
                additional_info = "(no chem. feats, most_interactions)")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_moa_modelled_is_truth_mostinteractions.pdf", width = 16)

foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "all") %>%
   select(-one_of("PredData", "auc_stabilities", "auc_stabilities_new")) %>%
   unnest()

plot_auc_vs_moa(foo, xaxis = "feat_preselect", yaxis = "prob.moa_sd2", 
                colourvar = "moa_modelled_is_truth", 
                facet_expr = quote(facet_grid(fitted_model ~ process_broad)), 
                additional_info = "(no chem. feats, all dosages)")

# ggsave(plot = p, filename = "./plots/Prob_stabilities_moa_modelled_is_truth_alldosages.pdf", width = 16)
```

Conclusion: predictions where drug MoA == MoA modelled are more stable except for lasso where it's 
vice versa. Interestingly, with all dosages, predictions where MoA == moa_modelled get a lot more 
unstable for RF. 


## Selected ROC/precision-recall curves

Random forests and lasso. 
Moreover, take with chemical features and using all dosages. Finally, top25pct/keepall seemed to 
be decent feature preselections. So what do the ROC curves look like? 

```{r}
tmp <- filter(matrix_container, 
              fitted_model %in% c("classif.randomForest", "classif.glmnet"), 
              feat_preselect %in% c("top25pct", "keepall"), 
              chemical_feats, 
              drug_dosages == "all")

plot_ROC_from_container(tmp[tmp$fitted_model == "classif.randomForest", ])
plot_ROC_from_container(tmp[tmp$fitted_model == "classif.glmnet", ])


tmp <- filter(matrix_container, 
              fitted_model %in% c("classif.randomForest", "classif.glmnet"), 
              feat_preselect %in% c("top25pct", "keepall"), 
              ! chemical_feats, 
              drug_dosages == "all")

plot_ROC_from_container(tmp[tmp$fitted_model == "classif.randomForest", ])

# # check if AUCs are correct:
# stability_assessment %>% 
#    filter(fitted_model == "classif.randomForest", 
#           feat_preselect %in% c("top25pct", "keepall"), 
#           chemical_feats, 
#           drug_dosages == "all") %>% 
#    select(-one_of("prob.moa_stabilities", "auc_stabilities", "PredData")) %>%
#    unnest() %>%
#    group_by(fitted_model, feat_preselect, moa_modelled) %>% 
#    summarise(mean_auc = mean(auc))
# 
# # they are sometimes a bit off - no idea why - rounding? 
```

Note: for cell_wall/dna/protein_synthesis: even though lasso and random forests are very similar 
for total AUCs (check top25pct), ROC curve shapes and, consequently, partial AUCs (see also above) 
show that random forests performs a lot better. Only for membrane_stress, lasso is the clear winner. 
But note the issue with probabilities, showing ROC curves for each repeat might still be useful. 

To be complete, here the precision-recall curves: 

```{r}
plot_precRecall_from_container(tmp[tmp$fitted_model == "classif.randomForest", ])
plot_precRecall_from_container(tmp[tmp$fitted_model == "classif.glmnet", ])
```

? Why do they not start at 1? Not apparent from ROC-curves. 

## Selected AUC/partial AUC comparison

There may be reasons though to work without chemical features and fewer dosages (see below). This 
would impact our performances as follows. I'm taking only top25pct and keepall for simplicity as 
they are the best feat_preselect cases depending on the MoA. 

```{r}
tmp <- 
   stability_assessment %>%
   filter(fitted_model %in% c("classif.randomForest", "classif.glmnet"), 
          drug_dosages == "all", 
          feat_preselect %in% c("top25pct", "keepall")) %>%
   select(-one_of("prob.moa_stabilities", "auc_stabilities", "PredData")) %>%
   unnest()

plot_auc_vs_moa(tmp, xaxis = "moa_modelled", yaxis = "auc", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(feat_preselect ~ fitted_model)), additional_info = "")
```

So one may be able to compensate for the loss of chemical features by using lasso. Here are the 
partial AUCs:

```{r}
plot_auc_vs_moa(tmp, xaxis = "moa_modelled", yaxis = "part_auc_01", colourvar = "chemical_feats", 
                facet_expr = quote(facet_grid(feat_preselect ~ fitted_model)), additional_info = "")
```


## Further investigations on drug dosages

### Distributions of dosages among drugs

It looks like using all dosages is better than most_interactions. At the same time, it seems 
plausible that some dosages will be "wrong" in terms of having a too low drug dosage. Moreover, 
some drugs were tested with only 1 dosage, others with 6, which would lead to an overweighting of 
the latter drugs. Perhaps there is a compromise such as using the 2 dosages with most interactions? 
Also, it'd be interesting to see if there is a correlation of the number of interactions and 
prediction probabilities. 

How does number of dosages distribute among the different drugs and MoA?

```{r}
# take a drug_feature_matrix which has all dosages and all drugs etc. 
tmp <- matrix_container$drug_feature_matrices[[1]]
tmp <- 
   select(tmp, drugname_typaslab, conc, process_broad) %>%
   group_by(drugname_typaslab, process_broad) %>%
   summarise(ndosages = n())

ggplot(tmp, aes(x = process_broad, y = ndosages, colour = process_broad)) + 
   ggbeeswarm::geom_beeswarm(groupOnX = TRUE, size = 2, cex = 1.5) + 
   theme_bw() + 
   theme(text = element_text(size = 18), axis.text.x = element_text(size = 18, angle = 45, hjust = 1))

tapply(tmp$ndosages, tmp$process_broad, mean)
```


### Correlating the number of significant interactions per drug with prediction probabilities

From the ultimate plot it seems like the dosages with the most interactions might also be the ones 
that are best at predicting a particular MoA. However, the trend is not crystal clear. Moreover, we 
don't know how many interactions this actually corresponds to. In addition, one may wonder whether 
some poorly predicted drugs are poorly predicted because they show only very few interactions even 
with "most_interactions". 


#### Preparing the data

This is a bit tricky because we need to get `the_matrix` from the first notebook ("1_DataLoading...") 
after the `do(select_mutant(.))` step because it contains the qvalue for each drug-gene-concentration 
combination. For each drug-dosage combination in each of the models we built the number of 
significant interactions will depend on the number of features that have been preselected. 

```{r, message = FALSE}
# the_matrix <- readRDS("./data/the_matrix_after_select_mutant.rds")
the_matrix <- readRDS("./data/programmatic_output/the_matrix_complete_strainsgenesremoved.rds")

# add a new list column to matrix_container_ext: similar to PredData but with median of prob.moa 
# and indicating how many significant interactions there are per drug and concentration using the 
# drug_feature_matrix that was used for that particular model 

if (file.exists("./data/programmatic_output/matrix_container_ext.rds")) {
   matrix_container_ext <- readRDS("./data/programmatic_output/matrix_container_ext.rds")
} else {
   matrix_container_ext$PredDataWithNSignif <- 
      map2(matrix_container_ext$drug_feature_matrices, matrix_container_ext$PredData, 
           get_nsignif, 
           the_matrix = the_matrix)
   saveRDS(matrix_container_ext, "./data/programmatic_output/matrix_container_ext.rds")
}
```

#### Investigating number of interactions and class probabilities

General question: is there something like a minimum number of significant interactions to get 
useful predictions? 

We check here for both random forests and lasso trained with all features, and without chemical 
features.

```{r}
# any model with keepall is fine here
tmp <- filter(matrix_container_ext, fitted_model == "classif.randomForest", 
              feat_preselect == "keepall", chemical_feats == FALSE, drug_dosages == "all")
stopifnot(nrow(tmp) == 1)
tmp <- tmp$PredDataWithNSignif[[1]]

ggplot(tmp, aes(x = n_signif, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   facet_grid(moa_modelled ~ moa_modelled_is_truth) + 
   theme_bw() + 
   theme(text = element_text(size = 18)) + 
   labs(x = "Number of significant interactions", y = "Median probability for MoA for each drug", 
        title = "Probabilities (y-axis) for MoA (right side) vs. number of sign. IAs (x-axis)\n(RF, all dosages, no chem feats, keepall)")

tmp <- filter(matrix_container_ext, fitted_model == "classif.glmnet", 
              feat_preselect == "keepall", chemical_feats == FALSE, drug_dosages == "all")
stopifnot(nrow(tmp) == 1)
tmp <- tmp$PredDataWithNSignif[[1]]

ggplot(tmp, aes(x = n_signif, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   facet_grid(moa_modelled ~ moa_modelled_is_truth) + 
   theme_bw() + 
   theme(text = element_text(size = 18)) + 
   labs(x = "Number of significant interactions", y = "Median probability for MoA for each drug", 
        title = "Probabilities (y-axis) for MoA (right side) vs. number of sign. IAs (x-axis)\n
        (Lasso, all dosages, no chem feats, keepall)")

```

So there seems to be a trend, but only for cell_wall and dna. Interestingly, lasso seems to have 
different levels of a "background" probability for certain MoAs if moa_modelled != actual MoA. 

But what about _within_ drugs? Do predictions profit from taking concentration with higher number 
of significant interactions? Exclude drugs with just one dosage. 

First check how n_signif ranks and conc_ranks correlate.

```{r}
# exclude cases where moa_modelled != truth and drugs with just one concentration
tmp2 <- tmp[tmp$moa_modelled_is_truth & tmp$n_conc > 1, ]

ggplot(tmp2, aes(x = conc_rank, y = n_signif_rank)) + 
   geom_count() + 
   labs(title = "Ranks of number of significant interactions vs. ranks of concentrations, all drugs
        \n(cases with just one concentration excluded)")

cor(tmp2$conc_rank, tmp2$n_signif_rank, method = "spearman")

# novobiocin, for example:
filter(tmp2, drugname_typaslab == "NOVOBIOCIN")
```

Now compare prediction probabilities vs. ranks.

```{r}
ggplot(tmp2, aes(x = n_signif_rank, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   geom_line(aes(group = drugname_typaslab)) + 
   facet_grid(moa_modelled ~ n_conc) + 
   labs(title = "Median probability vs. concentration rank. Each line is a drug.")

ggplot(tmp2, aes(x = conc_rank, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   geom_line(aes(group = drugname_typaslab)) + 
   facet_grid(moa_modelled ~ n_conc) + 
   labs(title = "Median probability vs. n_signif interaction rank. Each line is a drug.")
```

It looks like it would actually be better to just take the two highest concentrations. This is also 
what a correlation test says:

```{r}
cor(x = tmp2$n_signif_rank, y = tmp2$median_prob.moa, method = "spearman")
cor(x = tmp2$conc_rank, y = tmp2$median_prob.moa, method = "spearman")
```

How do average probabilities change if we take the two dosages with most interactions/the two 
highest concentrations vs. the other dosages/concentrations? 

```{r}
tmp3 <- 
   tmp2 %>%
   group_by(moa_modelled, drugname_typaslab) %>%
   mutate(most2interactions = n_signif_rank %in% sort(n_signif_rank, decreasing = TRUE)[1:2]) %>% 
   # split into 2 groups: two highest interactions and all lower dosages
   filter(n() > 2) %>% # keep only drugs where we can actually compare the effects
   group_by(drugname_typaslab, moa_modelled, most2interactions) %>% # summarise within those groups
   summarise(mean.median_prob.moa = mean(median_prob.moa)) %>%
   ungroup()

ggplot(tmp3, aes(x = most2interactions, y = mean.median_prob.moa, colour = most2interactions)) + 
   geom_boxplot() + 
   geom_point() +
   geom_line(aes(group = drugname_typaslab), colour = "black") + 
   facet_wrap( ~ moa_modelled) + 
   labs(title = "Effect of using 2 dosages with most interactions (= label 'TRUE')\nvs. other 
        dosages (= label 'FALSE')")


tmp3 <- 
   tmp2 %>%
   group_by(moa_modelled, drugname_typaslab) %>%
   mutate(two_highest_dosgs = conc_rank %in% sort(conc_rank, decreasing = TRUE)[1:2]) %>% 
   # split into 2 groups: two highest concentrations and all lower dosages
   filter(n() > 2) %>% # keep only drugs where we can actually compare the effects
   group_by(drugname_typaslab, moa_modelled, two_highest_dosgs) %>% # summarise within those groups
   summarise(mean.median_prob.moa = mean(median_prob.moa)) %>%
   ungroup()

ggplot(tmp3, aes(x = two_highest_dosgs, y = mean.median_prob.moa, colour = two_highest_dosgs)) + 
   geom_boxplot() + 
   geom_point() +
   geom_line(aes(group = drugname_typaslab), colour = "black") + 
   facet_wrap( ~ moa_modelled) + 
   labs(title = "Effect of using 2 highest concentrations (= label 'TRUE')\nvs. other concentrations (= label 'FALSE')")
```

Another argument against using all dosages is that it leads to a higher degree of correlation of 
the features between the observations: within dosage correlation is significantly higher than 
between dosage correlation (see notebook "Misc.Rmd") so our degree of dependency between 
observations is likely to drop. 
<!--
Open points: 
- Correlation of median_prob.moa and ranks should perhaps be done for individual drugs and across
  all models. 
- The concentration with "highest number of interactions" is based on "keepall". How often is it 
  different from the actual concentration with highest number of interactions using a specific 
  feature selection?
-->

## Further investigations on chemical features

First thing to note is that there is a considerable correlation between the chemical featues we use 
for the drugs in our data set. High correlation between features is problematic for a number of 
reasons: first, they indicate redundant information. Second, it can lead to model instability (cf. 
pages 12, 46 in Kuhn & Johnson, 2013). 

To show how strongly the chemical features are correlated:

```{r}
tmp <- matrix_container[180, ]
stopifnot(nrow(tmp) == 1 & tmp$drug_dosages == "most_interactions" & tmp$chemical_feats)
tmp <- tmp$drug_feature_matrices[[1]]

# we have 13 chemical features
tmp_m <- select(tmp, (ncol(tmp)-12):ncol(tmp))
tmp_m <- as.matrix(tmp_m)
row.names(tmp_m) <- tmp$drugname_typaslab
tmp_m_cor <- cor(tmp_m)

corrplot::corrplot(tmp_m_cor, method = "color", order = "hclust", tl.cex = 0.7)
corrplot::corrplot(tmp_m_cor, type = "upper", method = "number", order = "hclust", tl.cex = 0.4)
```

As can also be seen in the plot "drug_drug_similarities_RDKit.pdf" (notebook Misc) our chemical 
features are biased towards distinguishing protein_synthesis from the other features:

```{r}
select(tmp, drugname_typaslab, process_broad, (ncol(tmp)-12):ncol(tmp)) %>%
   filter(process_broad %in% c("cell_wall", "dna", "protein_synthesis", "membrane_stress")) %>%
   gather(-drugname_typaslab, -process_broad, key = "chemical_feature", value = "value") %>%
   ggplot(aes(x = process_broad, y = value, colour = process_broad)) + 
      ggbeeswarm::geom_beeswarm(groupOnX = TRUE, cex = 2, shape = 1) + 
      facet_wrap( ~ chemical_feature, ncol = 5, scales = "free_y") + 
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
      labs(title = "Distribution of chemical features across MoAs")
```



## Exploring matrix_container_new

```{r exploring_matrix_container_new}
stability_assessment_new <- readRDS("./data/stability_assessment_newmatrixcontainer.rds")

tmp <- 
   select(stability_assessment_new, drug_dosages:hyperparam_grid_name, auc_stabilities_new) %>%
   unnest()

# aucs
plot_auc_vs_moa(tmp, xaxis = "moa_modelled", yaxis = "auc", colourvar = "fitted_model", 
                facet_expr = quote(facet_wrap( ~ feat_preselect, ncol = 3)), additional_info = "")

# partial aucs
plot_auc_vs_moa(tmp, xaxis = "moa_modelled", yaxis = "part_auc_01", colourvar = "fitted_model", 
                facet_expr = quote(facet_wrap( ~ feat_preselect, ncol = 3)), additional_info = "")


tmp <- 
   select(stability_assessment_new, drug_dosages:hyperparam_grid_name, prob.moa_stabilities) %>%
   unnest() %>%
   filter(moa_modelled_is_truth) %>%
   left_join(drug_feature_matrix[, c("drugname_typaslab", "process_broad")])

plot_auc_vs_moa(tmp, xaxis = "process_broad", yaxis = "prob.moa_sd2", colourvar = "fitted_model", 
                facet_expr = quote(facet_wrap( ~ feat_preselect, ncol = 3)), additional_info = "")
```


# System and session info

```{r, session_info}
R.version
sessionInfo()
```



