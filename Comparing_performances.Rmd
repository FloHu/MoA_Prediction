---
title: "Comparing model performances"
author: "Florian Huber, Leonard Dubois"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

# Setup, library loading

This part is the general setup, whichever model we are using.

```{r setup}
# function to check if a package is installed, if so, load it, else install and then load it
source("./R/ipak.R")
# set chunk options and load libraries
source("./setup.R")
# custom functions
walk(list.files("./R", pattern = "*.R", full.names = T), source)
# library(cowplot)
# library(pryr)
```


# Data preparation

## Reading in `run_results_from_server`

On the cluster, each of the rows of `matrix_container` was run; each row was a different combination 
of models, feature preselections etc and was saved in a separate results object 
(`./run_results_from_server/matrix_container_result`). Since the results objects are too big for 
putting them into `matrix_container` we will add new columns just containing the parts we are 
interested in. 

```{r reading_in, message = FALSE}
# old matrix_container object
load("./data/matrix_container.RData")
matrix_container_old <- matrix_container

##################################################
##### ROUTINE TO READ IN ALL RESULTS OBJECTS #####
##################################################

# What follows is a loop to extract information from our results objects and adding this into 
# new columns. Since this takes some time, it's written in a way that the matrix_container can be 
# updated. 

# results we already have
if (file.exists("./data/matrix_container_withextractions.rds")) {
   matrix_container <- readRDS("./data/matrix_container_withextractions.rds")
   matrix_container.bak <- matrix_container
   matrix_container <- matrix_container.bak
} else {
   matrix_container$hyperparam_grid_name <- names(matrix_container$hyperparam_grid)
   matrix_container$ThreshVsPerfData <- list(NA)
   matrix_container$PredData <- list(NA)
}

# available results files
available_files <- list.files("./run_results_from_server/matrix_container_result/", 
                              pattern = "xgboost|rf|lasso")
moas <- c("dna", "cell_wall", "protein_synthesis", "membrane_stress")

# loop to read in results files
for (rownum in seq_len(nrow(matrix_container))) {
   matrix_container_row <- matrix_container[rownum, ]
   # look for a file corresponding to a row
   targetfile <- paste(unlist(matrix_container_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_")
   targetfile <- paste0(targetfile, ".rds")
   my_match <- available_files[available_files == targetfile]
   
   # check if values are not defined: if yes: check if matching file exists or continue
   # if values are already defined means we parsed a corresponding results object previously so we 
   # can continue
   if ( any(is.na(unlist(matrix_container_row[, c("ThreshVsPerfData", "PredData")]))) ) {
      if (length(my_match) > 0) {
         cat("Match for unpopulated row ", rownum, "\t==>\t", my_match, "\n", sep = "")
      } else {
         cat("Didn't find a match for line ", rownum, ", continuing to next line.\n", sep = "")
         # warning("Didn't find a match for line ", rownum) # this doesn't work - no clue why - use cat()
         next
      }
   } else {
      cat("Row ", rownum, " already populated, continuing to next line.\n")
      next
   }
   
   resultsobj <- readRDS(paste0("./run_results_from_server/matrix_container_result/", my_match))
   
   # extract ThreshVsPerfData and prediction object data using some custom functions
   matrix_container$ThreshVsPerfData[[rownum]] <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = perf_extractor)
   
   # get prediction data, add drug name information and concentration
   pred_data <- map_dfr(moas, prediction_merger, res = resultsobj, extractorfunc = pred_extractor)
   pred_data$drugname_typaslab <- (matrix_container_row$drug_feature_matrices[[1]])$drugname_typaslab[pred_data$id]
   pred_data$conc <- (matrix_container_row$drug_feature_matrices[[1]])$conc[pred_data$id]
   matrix_container$PredData[[rownum]] <- pred_data
}

#  update
saveRDS(matrix_container, file = "./data/matrix_container_withextractions.rds")

# to get an example of a results object
my_row <- matrix_container[1, ]
(my_filename <- paste(unlist(my_row[, c("hyperparam_grid_name", "drug_dosages", "feat_preselect", "chemical_feats")]), collapse = "_"))
my_filename <- paste0("./run_results_from_server/matrix_container_result/", my_filename, ".rds")
stopifnot(file.exists(my_filename))
example_res <- readRDS(my_filename)
rm(my_row, my_filename)
```


## Adding more information - `matrix_container_ext`

Add information about MoA for each drug and which dosage is the dosage with most interactions. 
Replace all MoAs not being one of dna, membrane_stress, protein_synthesis, and cell_wall with 
"other". Results in object `matrix_container_ext`. 

```{r matrix_container_ext}
# remove NA rows
matrix_container_ext <- matrix_container[!is.na(matrix_container$PredData), ]

# we need a drug feature matrix for some of our annotations
drug_feature_matrix <- 
   filter(matrix_container, drug_dosages == "most_interactions", feat_preselect == "keepall", 
          chemical_feats == FALSE, fitted_model == "classif.randomForest") %>%
   pull(drug_feature_matrices) %>%
   map_dfr(identity)

stopifnot(nrow(drug_feature_matrix) < 100)

# add process_broad to each prediction data frame
matrix_container_ext$PredData <- 
   map2(matrix_container_ext$PredData, matrix_container_ext$drug_feature_matrices, function(.x, .y) {
      # get process_broad (moa) for each drug
      .x$process_broad <- .y$process_broad[.x$id] 
      return(.x)
   })

# beware! dosage with "most interactions" refers to the "keepall" features, as we can see here:
nrow(
   filter(matrix_container, drug_dosages == "most_interactions") %>%
   pull(drug_feature_matrices) %>%
   map_dfr(~ .x[, c("drugname_typaslab", "conc")]) %>%
   distinct()
)

# reference data frame from which we get the information which dosage has most interactions
most_interactions <- drug_feature_matrix[, c("drugname_typaslab", "conc")]

# add a column indicating which dosage is the one with most interactions
# also, replace moas not being "dna", "cell_wall", "membrane_stress", or "protein_synthesis" with "other"
matrix_container_ext$PredData <- 
   map(matrix_container_ext$PredData, function(.x) {
      # make vector indicating if the current concentration is the one with most interactions by temporary joining with our reference data frame
      conc_mostias <- 
         select(.x, drugname_typaslab, conc) %>%
         left_join(most_interactions, by = c("drugname_typaslab" = "drugname_typaslab"), suffix = c(".origin", ".mostias")) %>%
         mutate(conc.origin.is.mostias = (conc.origin == conc.mostias)) %>%
         pull(conc.origin.is.mostias)
      .x$conc_mostias <- conc_mostias
      .x$process_broad <- ifelse(.x$process_broad %in% c("dna", "cell_wall", "membrane_stress", "protein_synthesis"), 
                                 .x$process_broad, 
                                 "other")
      return(.x)
   })

# sanity check: is there just one concentration with most interactions per drug? 
# 40: because of 10 repeats and each drug being part of 4 models (one for each MoA)
stopifnot(length(unique(matrix_container_ext$PredData[[1]]$drugname_typaslab)) == sum(matrix_container_ext$PredData[[1]]$conc_mostias)/40)
```

For each model, each drug is predicted to have a certain probability to belong to each MoA. Since 
we did repeated nested CV, we can ask how stable these probabilities are. The same we can ask for 
auc measurements. To ask these questions, we make a table `stability_assessment`. We need a separate 
table to combine information for each repeat of the nested CV with unnesting to easily plot grouping 
variables. This table will also indicate whether `moa_modelled == moa_truth` or not as we want to 
compare stabilities of parameters depending on whether the drug actually belongs to the MoA we are 
trying to predict. We exclude all drugs with "other". 

```{r stability_assessment_table_I}
# write into a new table stability_assessment 
# here comes just an example of what this table will look like 
# these are the input data for *one* model
input_dat_exmpl <- matrix_container_ext$PredData[[1]]
head(input_dat_exmpl)

get_prob.moa_sds <- function(predDataTbl) {
   # take prediction data ("predDataTbl") and get for each drug the sd of the probabilities for which it is predicted 
   # to be a particular moa, once if moa_modelled == moa_actual and once moa_modelled != moa_actual 
   avg_sd_by_moa <- 
      predDataTbl %>%
      mutate(moa_modelled_is_truth = (moa_modelled == process_broad)) %>% # to distinguish the two cases 
      group_by(drugname_typaslab, moa_modelled_is_truth) %>% # we want to see stability for each drug depending on whether moa_modelled_is_truth 
      summarise(process_broad = unique(process_broad), prob.moa_sd = sd(prob.moa)) %>%
      filter(process_broad != "other") # let's not consider these cases for now
   return(avg_sd_by_moa)
}
```

Here an example of what this looks like:

```{r stability_assessment_table_II}
get_prob.moa_sds(input_dat_exmpl)

# just to make sure it is correct (! we average over all dosages here)
get_prob.moa_sds(input_dat_exmpl)[2, "prob.moa_sd"]
# ... which should be equivalent to:
filter(input_dat_exmpl, drugname_typaslab == "A22", moa_modelled == process_broad) %>%
   pull(prob.moa) %>%
   sd()

## and now apply this to each model:
stability_assessment <- 
   matrix_container_ext %>% 
   select(drug_dosages, feat_preselect, chemical_feats, fitted_model, hyperparam_grid_name, PredData) %>%
   mutate(prob.moa_stabilities = map(PredData, get_prob.moa_sds))


## do the same thing now for aucs
# again, here is an example:
get_aucs_per_repeat <- function(predDataTbl) {
   #### TO DO: extract concatenated results objects already at the beginning, then they can be coerced to ROCR objects to get partial AUCs
   # take threshVsPerfData and calculate auc for each repeat and each moa
   aucs <- 
      predDataTbl %>%
      mutate(negative = paste0("not_", moa_modelled)) %>%
      group_by(cvrep, moa_modelled) %>%
      summarise(auc = measureAUC(probabilities = prob.moa, truth = truth, negative = negative, positive = moa_modelled)) %>% 
      ungroup()
   return(aucs)
}

# example output
get_aucs_per_repeat(input_dat_exmpl)

# and apply again to each model
stability_assessment$auc_stabilities <- map(stability_assessment$PredData, get_aucs_per_repeat)

# for ordering in plots
stability_assessment$feat_preselect <- 
   factor(stability_assessment$feat_preselect, 
          levels =  c("top5pct", "top10pct", "top15pct", "top20pct", "top25pct", "top30pct", 
                      "top40pct", "top50pct", "keepall"))
```


# Data analyses

## Model stabilities 

### Distribution of probabilities, aka 'ultimate plot' 

Shows the distribution of probabilities for each drug across repeats of the nested CV. Can plot 
only one model at a time. Grey rectangles indicate the dosage with the most interactions. 

```{r ultimate_plots, eval = FALSE}
# Let's start with 2 ultimate plots for now: random forests, keepall, no chemical features, all dosages
# (what we discussed with Nassos)
# other stuff to come later
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.randomForest", drug_dosages == "all")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_alldosages_nochemfeats.pdf")

# let's try also for one of the lasso models
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.glmnet", drug_dosages == "all")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_alldosages_nochemfeats.pdf")

# and now both of them with just the "most_interactions" dosage
tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.randomForest", drug_dosages == "most_interactions")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_RF_keepall_mostinteractions_nochemfeats.pdf")


tmp <- filter(matrix_container_ext, feat_preselect == "keepall", chemical_feats == FALSE, 
              fitted_model == "classif.glmnet", drug_dosages == "most_interactions")

ultimate_plot_new(tmp, filename = "./plots/ultimate_plot_LASSO_keepall_mostinteractions_nochemfeats.pdf")
```


### Stabilities of probabilities 

The plot above is good for understanding the behaviour within a model but bad for getting an overall 
idea of how stable predictions are. For this, calculate the standard deviation of the probabilities 
assigned to each drug for each mode of action. Different dosages will be lumped together. 


#### Stabilities of probabilities: impact of feat_preselect

When fixing the following:
* chemical_feats == FALSE
* drug_dosages == "most_interactions"
* moa_modelled == truth
--> What is the impact of feat_preselect on model stability, depending on the model type and the 
hyperparameter grid?

```{r, fig.width = 10, fig.height = 7}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "auc_stabilities")) %>%
   unnest() %>%
   filter(moa_modelled_is_truth)
head(foo)

p <- 
   ggplot(foo, aes(x = process_broad, y = prob.moa_sd)) + 
   geom_boxplot(aes(colour = feat_preselect), position = position_dodge(), outlier.shape = NA) + 
   geom_point(position = position_jitterdodge(jitter.width = 0.2), aes(colour = feat_preselect), size = 1, alpha = 0.5) + 
   # geom_beeswarm(aes(colour = feat_preselect), size = 1, alpha = 0.75) + # doesn't work :(
   geom_vline(xintercept = c(1.5, 2.5, 3.5), linetype = "dotted") + 
   facet_grid(fitted_model ~ .) + 
   labs(x = "Mode of action modelled", y = "Standard deviation of probabilities", 
        title = "Stabilities of MoA predictions, each drug = one point\n(no chem. feats, most_interactions, MoA modelled = MoA truth)") + 
   theme_bw()
p
ggsave(plot = p, filename = "./plots/Prob_stabilities_by_feat_preselect.pdf", width = 10, height = 7)


# What about 'classif.xgboost'? - Possible that stabilities depend on hyperparameter grid?
p <- 
   ggplot(foo[foo$fitted_model == "classif.xgboost", ], aes(x = process_broad, y = prob.moa_sd)) + 
   geom_boxplot(aes(colour = feat_preselect), position = position_dodge(), outlier.shape = NA) + 
   geom_point(position = position_jitterdodge(jitter.width = 0.2), aes(colour = feat_preselect), size = 1, alpha = 0.5) + 
   geom_vline(xintercept = c(1.5, 2.5, 3.5), linetype = "dotted") + 
   facet_grid(hyperparam_grid_name ~ .) + 
   labs(x = "Mode of action modelled", y = "Standard deviation of probabilities", 
        title = "Stabilities of MoA predictions: classif.xgboost only\n(no chem. feats, most_interactions, MoA modelled = MoA truth)") + 
   theme_bw()
p
ggsave(plot = p, filename = "./plots/Prob_stabilities_by_feat_preselect_onlyxgboost.pdf")
```

Conclusion: No apparent correlation between feat_preselect and stabilities of probabilities. 
Random forests is the most stable model, lasso the least stable one although the latter 
has a big difference between individual drugs. Boosted trees is in between and there stabilities 
don't seem to differ between different hyperparameter grids. 


#### Stabilities of probabilities: impact of all dosages vs. most_interactions

Just like above, except that we now want to see whether models become more or less stable if all 
dosages are used or only one dosage with most interactions. 

```{r, fig.width = 16, fig.height = 10}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE) %>%
   select(-one_of("PredData", "auc_stabilities")) %>%
   unnest() %>%
   filter(moa_modelled_is_truth)
head(foo)

p <- ggplot(foo, aes(x = feat_preselect, y = prob.moa_sd)) + 
   geom_boxplot(aes(colour = drug_dosages)) + 
   facet_grid(process_broad ~ fitted_model) + 
   labs(x = "Feature preselection", y = "Standard deviation of probabilities", 
        title = "Stabilities of MoA predictions: all dosages vs. most_interactions\n(no chem. feats, MoA modelled = MoA truth)") + 
   theme_bw() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))
p

ggsave(plot = p, filename = "./plots/Prob_stabilities_all_vs_mostinteractions.pdf", width = 16)

# focus again only on classif.xgboost
p <- 
   ggplot(foo[foo$fitted_model == "classif.xgboost", ], aes(x = process_broad, y = prob.moa_sd)) + 
   geom_boxplot(aes(colour = drug_dosages), position = position_dodge(), outlier.shape = NA) + 
   geom_point(position = position_jitterdodge(jitter.width = 0.2), aes(colour = drug_dosages), size = 1, alpha = 0.5) + 
   geom_vline(xintercept = c(1.5, 2.5, 3.5), linetype = "dotted") + 
   facet_grid(hyperparam_grid_name ~ feat_preselect) + 
   labs(x = "Mode of action modelled", y = "Standard deviation of probabilities", 
        title = "Stabilities of MoA predictions: all dosages vs. most_interactions\n(no chem. feats, MoA modelled = MoA truth,\nXGBoost only)") + 
   theme_bw()
p

ggsave(plot = p, filename = "./plots/Prob_stabilities_all_vs_mostinteractions_onlyxgboost.pdf", width = 16)
```

Conclusion: most interactions is a lot more stable for random forests and less so for boosted trees. 
For lasso there is also a trend to be more stable with most interactions but it's less clear and 
depends on the mode of action. Again, there is no influence of the hyperparameter grid used for boosted trees. 

Interestingly: stabilities change a bit between MoAs for random forests but only if all dosages are 
used, not if just most_interactions are used, which would be another argument for using just one 
dosage. 

Why are stabilities quite different between MoAs between the MoAs, especially for lasso? Why are 
most_interactions a lot more stable for RF but only a bit more stable for lasso? Can we conclude 
anything from the stability differences between MoAs for the lasso or is this just the normal noise 
of the model. 


#### Stabilities of probabilities: impact of whether MoA modelled = truth

Like above but this time we do not focus on the probabilities where the MoA that was being modelled 
is the same as the MoA of the drug. So we ask whether drugs are more stably predicted to be their 
MoA or whether they are more stably predicted to be not their MoA. Check once for all dosages and 
once for most_interactions. 

```{r, fig.width = 16, fig.height = 10}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "auc_stabilities")) %>%
   unnest()

p <- ggplot(foo, aes(x = feat_preselect, y = prob.moa_sd)) + 
   geom_boxplot(aes(colour = moa_modelled_is_truth), outlier.size = 1) + 
   facet_grid(process_broad ~ fitted_model) + 
   labs(x = "Feature preselection", y = "Standard deviation of probabilities", 
        title = "Stabilities of MoA predictions: MoA modelled = truth or not\n(no chem. feats, most_interactions)") + 
   theme_bw() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))
p

ggsave(plot = p, filename = "./plots/Prob_stabilities_moa_modelled_is_truth_mostinteractions.pdf", width = 16)


foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "all") %>%
   select(-one_of("PredData", "auc_stabilities")) %>%
   unnest()

p <- ggplot(foo, aes(x = feat_preselect, y = prob.moa_sd)) + 
   geom_boxplot(aes(colour = moa_modelled_is_truth), outlier.size = 1) + 
   facet_grid(process_broad ~ fitted_model) + 
   labs(x = "Feature preselection", y = "Standard deviation of probabilities", 
        title = "Stabilities of MoA predictions: MoA modelled = truth or not\n(no chem. feats, all dosages)") + 
   theme_bw() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))
p

ggsave(plot = p, filename = "./plots/Prob_stabilities_moa_modelled_is_truth_alldosages.pdf", width = 16)
```

Conclusion: if most interactions are kept: predictions where drug MoA = MoA modelled are more stable 
except for lasso where it's vice versa. Interestingly, with all dosages, predictions where MoA == 
moa_modelled get a lot more unstable for RF. 



### Comparing AUCs across all models

Which models have the best AUCs and how does it change between models, feature_preselections and so 
on. Also allows assessing how stable AUCs are across repetitions of nested CV. 

#### AUCs/AUC stabilities by feat_preselect 

Without chemical features, using most_interactions. 

```{r, fig.width = 16, fig.height = 10}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE, drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

p <- 
   ggplot(foo, aes(x = moa_modelled, y = auc)) + 
   geom_boxplot(aes(colour = feat_preselect), position = position_dodge(), outlier.shape = NA) + 
   geom_point(position = position_jitterdodge(jitter.width = 0.1), aes(colour = feat_preselect), size = 1, alpha = 0.5) + 
   geom_vline(xintercept = c(1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5), linetype = "dotted") + 
   facet_grid(fitted_model ~ .) + 
   labs(x = "Mode of action modelled", y = "AUC (one dot per repeat of nested CV)", 
        title = "AUCs of MoA predictions\n(no chem. feats, most_interactions)") + 
   theme_bw()
p

ggsave(plot = p, filename = "./plots/AUC_stabilities_mostinteractions.pdf", width = 16)
```

Conclusion: it depends on the MoA:
* `cell_wall` performs best overall and is relatively stable. top15pct seems to be better for RF 
whereas top5pct is best for lasso. For lasso performance seems to drop slightly with the higher number of 
features that are kept. 
* `dna` also has a decent performance which is again quite stable. For lasso again the performance 
seems to drop slightly with the increasing number of features. But perhaps it also just reflects the 
instability of the lasso model as performance goes up again later on. 
* `protein_synthesis` performs poorly for RF and lasso with top5 and top10pct but performance goes 
up with top15pct (RF) and top20pct (lasso), respectively. 
* `membrane_stress` has overall the worst performance and is also the least stable. 

When looking closely: cell_wall and dna are a bit more stable with RF. 

The best compromise across lasso and RF would probably be top15pct. RF and lasso perform similarly 
well, lasso perhaps only because of being less stable? 


#### AUCs: all dosages vs. most_interactions

```{r, fig.width = 16, fig.height = 10}
foo <- 
   stability_assessment %>%
   filter(chemical_feats == FALSE) %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()
head(foo)

p <- 
   ggplot(foo, aes(x = feat_preselect, y = auc, colour = drug_dosages)) + 
   geom_boxplot(position = position_dodge(), outlier.shape = NA) + 
   geom_point(position = position_jitterdodge(jitter.width = 0.1), size = 1) + 
   facet_grid(moa_modelled ~ fitted_model) + 
   labs(x = "Mode of action modelled", y = "AUC (one dot per repeat of nested CV)", 
        title = "AUCs of MoA predictions: all dosages vs. most_interactions\n(no chem. feats)") + 
   theme_bw() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))
p

ggsave(plot = p, filename = "./plots/AUC_stabilities_alldosages_vs_mostinteractions.pdf", width = 16, height = 10)
```

Conclusions: 
* RF: 
   + cell_wall and dna: most_interactions performs slightly better. 
   + For membrane_stress, most_interactions almost always performs worse. 
   + For protein_synthesis most_interactions performs worse up to top15pct and for higher feature numbers it's very similar. 
* Lasso: 
   + cell_wall: aucs are very similar up to top20pct, after that, most_interactions gets worse. 
   + dna: up top 20pct, most_interactions performs better, later on similar. 
   + membrane_stress: most_interactions sometimes worse, sometimes equal - it depends.
   + protein_synthesis: most_interactions almost always performs worse. 

Could this be an effect of increased specificity with many dosages? 


#### AUCs: with and without chemical features (only looking at most_interactions)

```{r, fig.width = 16, fig.height = 10}
foo <- 
   stability_assessment %>%
   filter(drug_dosages == "most_interactions") %>%
   select(-one_of("PredData", "prob.moa_stabilities")) %>%
   unnest()

p <- 
   ggplot(foo, aes(x = feat_preselect, y = auc, colour = chemical_feats)) + 
   geom_boxplot(position = position_dodge(), outlier.shape = NA) + 
   geom_point(position = position_jitterdodge(jitter.width = 0.1), size = 1) + 
   facet_grid(moa_modelled ~ fitted_model) + 
   labs(x = "Mode of action modelled", y = "AUC (one dot per repeat of nested CV)", 
        title = "AUCs of MoA predictions: with vs. without chemical features\n(most_interactions)") + 
   theme_bw() + 
   theme(axis.text.x = element_text(angle = 45, hjust = 1))
p

ggsave(plot = p, filename = "./plots/AUC_stabilities_plusminus_chemical_feats.pdf", width = 16, height = 10)
```

Conclusions: chemical features bring big improvement in performance for protein_synthesis and, 
for occasional repeats, for membrane_stress. However, this is only true for low numbers of features. 



### Correlating the number of significant interactions per drug with prediction probabilities

From the ultimate plot it seems like the dosages with the most interactions are also often the ones 
that are best at predicting a particular MoA. However, this is not always the case. Moreover, we 
don't know how many interactions this actually corresponds to. In addition, one may wonder whether 
some poorly predicted drugs are poorly predicted because they show only very few interactions even 
with "most_interactions". 


#### Preparing the data

This is a bit tricky because we need to get `the_matrix` from the first notebook ("1_DataLoading...") 
after the `do(select_mutant(.))` step. In addition, the number of significant interactions will 
depend on the number of features that have been preselected. 

```{r, eval = FALSE}
the_matrix <- readRDS("./data/the_matrix_after_select_mutant.rds")

get_nsignif <- function(drugfeatmat, predDataTbl, the_matrix) {
   # drugfeatmat: from matrix_container_ext: the drug_feature matrix
   # predDataTbl: from matrix_container_ext: the prediction table
   # the_matrix: from first notebook: the_matrix after the do(select_mutant(.)) step
   drugfeatmat_long <- select(drugfeatmat, -process_broad) %>% gather(3:ncol(.), key = "gene_synonym", value = "sscore")
   
   # by doing a join we can do a lookup which drug-concentration-gene combination is significant
   tab_nsignif <- left_join(drugfeatmat_long, the_matrix) %>%
      group_by(drugname_typaslab, conc) %>%
      summarise(n_signif = sum(significant, na.rm = TRUE))
   
   # and now join this back into the predDataTbl object - which is what we need for plotting
   tab_nsignif <- left_join(predDataTbl, tab_nsignif)
   tab_nsignif$moa_modelled_is_truth <- tab_nsignif$moa_modelled == tab_nsignif$process_broad
   
   # in this case we're not interested in the probabilities for each repeat of the nested CV, only 
   # in the median
   tab_nsignif <- tab_nsignif %>%
      group_by(drugname_typaslab, conc, moa_modelled, moa_modelled_is_truth, n_signif) %>%
      summarise(median_prob.moa = median(prob.moa))
   
   return(tab_nsignif)
}

# add a new list column to matrix_container_ext: similar to PredData but with median of prob.moa 
# and indicating how many significant interactions there are per drug and concentration using the 
# drug_feature_matrix that was used for that particular model 
matrix_container_ext$PredDataWithNSignif <- 
   map2(matrix_container_ext$drug_feature_matrices, matrix_container_ext$PredData, get_nsignif, the_matrix = the_matrix)
```

Now we can test how prediction probabilities compare with number of significant interactions. Take 
again RF, all dosages, no chemical features, keepall (same as ultimate plot above). 

```{r, eval = FALSE}
tmp <- filter(matrix_container_ext, fitted_model == "classif.randomForest", feat_preselect == "keepall", 
              chemical_feats == FALSE, drug_dosages == "all")
stopifnot(nrow(tmp) == 1)
tmp <- tmp$PredDataWithNSignif[[1]]

ggplot(tmp, aes(x = n_signif, y = median_prob.moa)) + 
   geom_point(shape = 1) + 
   facet_grid(moa_modelled ~ moa_modelled_is_truth) + 
   theme_bw() + 
   labs(x = "Number of significant interactions", y = "Median probability for MoA for each drug", 
        title = "Probabilities (y-axis) for MoA (right side) vs. number of sign. IAs (x-axis)\n
        (RF, all dosages, no chem feats, keepall)")

ggsave(filename = "./plots/Probabilities_vs_NSignif_RF_all_nochemfeats_keepall.pdf")

ggplot(tmp[tmp$moa_modelled == "cell_wall" & tmp$moa_modelled_is_truth, ], 
       aes(x = n_signif, y = median_prob.moa, colour = drugname_typaslab)) + 
   geom_point(shape = 1) + 
   geom_line(aes(group = drugname_typaslab)) + 
   geom_text(aes(label = drugname_typaslab), hjust = 0, nudge_x = 0.05) + 
   facet_grid(moa_modelled ~ moa_modelled_is_truth) + 
   theme_bw()

ggsave(filename = "./plots/Probabilities_vs_NSignif_cell_wall.pdf")
```




# Exploring matrix container - ROC curves 


```{r, eval = FALSE, echo = FALSE}

resMatrix = readRDS("/Volumes/typas/Florian/matrix_container_withextractions.rds")

plot_ROC_from_container(containerObj = resMatrix[1:18, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix[19:36, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix[37:54, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix[55:72, ], moa = "all", by = c("feat_preselect", "chemical_feats"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "lasso_hyp_param"), moa = "all", by = c("feat_preselect", "drug_dosages"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "lasso_hyp_param"), moa = "all", by = c("feat_preselect", "drug_dosages"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "rf_hyp_param"), moa = "all", by = c("feat_preselect", "drug_dosages"))
plot_ROC_from_container(containerObj = resMatrix %>% filter(chemical_feats ==  TRUE, hyperparam_grid_name == "xgboost_hyp_param_std"), moa = "all", by = c("feat_preselect", "drug_dosages"))


```

