---
title: "Predicting drug mode of action: Boosting Tree model"
author: "Florian Huber, Leonard Dubois"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 6
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

# Setup, library loading

This part is the general setup, whichever model we are using.

```{r setup}
knitr::opts_chunk$set(echo = T)
knitr::opts_chunk$set(message = T)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(error = T)
knitr::opts_chunk$set(cache = T)
Sys.setlocale("LC_ALL", "en_IE.UTF-8")

library(tidyverse)
library(mlr)

#Custom functions
walk(list.files("./R", pattern = "*.R", full.names = T), source)

library("parallelMap") #Always useful
parallelStartMulticore(cpus = 3)

load(file = "the_matrix.RData")
the_matrix = merge(x = labels, y = the_matrix, by = "drugname_typaslab", all.y = T)
```

***

# Boosting tree Method

Boosting tree (BT) works in a similar way to Random Forest but trees are build sequentially. Each tree is a *weak* learner whose aim is to correct errors from the previous tree. In BT, trees present high bias and low variance and are sometimes as small as a decision stump (one root and two leaves). By aggregating these weak learners, one reduces bias.

## Setup - Loading

Learner used is `classif.boosting`, a classification learner based on boosting tree method and allowing multiclass probability prediction.
On top of `mlr` package, one should also install `adabag` and `rpart`.

```{r }
if(!require(adabag)){
    install.packages("adabag")
}
if(!require(rpart)){
    install.packages("rpart")
}
library(adabag)
library(rpart)

```

## Data preparation

Genes from Nichols chemogenomics data and KNIME chemical descriptors are included in the raw data matrix `the_matrix`

Here, the number of features is reduced by selecting only the ones whose Anova test beetween mode of action groups is significant. This means that the only features that remain are the ones able to seperate at least one mode of action from the others.

We then define the `task` object from `mlr` which is in this case a **classification** task with `process-broad` (**Mode of action**) as the outcome variable.

```{r}
#the_matrix_light = features_selection_anova(the_matrix, featStart = 3, groupColName = "process_broad")
the_matrix_light = feature_selection_variance(the_matrix, featStart = 3, percentTop = 10)

#Defining task : predicting drug mode of action, classification problem with more than 2 classes
predictMoa = makeClassifTask(data = select(the_matrix_light, -drugname_typaslab), target = "process_broad")
```


## Tuning (hyperparameters) - Preparation of the inner loop

```{r}
bt_hyp_param = makeParamSet(
    makeDiscreteParam("mfinal", values = seq(from = 20, to = 300, by = 20)), #number of trees
    makeDiscreteParam("maxdepth", values = c(1,2,3)), #1 is a stump, more than 3 = and it isn't a weak learner anymore. Even 3 might be too much
    
    ###############################
    makeDiscreteParam("coeflearn", values = c("Breiman", "Freund", "Zhu")) #Is it OK if in a Nested CV we use different "algorithms"
    ###############################
)

bt_tuning = makeTuneControlGrid()
inner = makeResampleDesc("CV", iters = 5, stratify = TRUE)
```

## Building learner

Wrapper of Learner allows us to create a custom learner whose inner CV for Hyperparameter tuning is already included inside it

```{r }
bt_learn = makeTuneWrapper("classif.boosting", resampling = inner, par.set = bt_hyp_param, control = bt_tuning )
```



## Tuning application (inner CV of the nested CV)

```{r}

outer = makeResampleDesc("CV", iters = 5, stratify = TRUE)

#Extract featureImportance is needed to answer the biological questions
#Models = TRUE might not be a so good idea for all models and all details of each will be kept in memory. This could generate tens of Gigabytes 
bt_expr = quote(res <- resample(learner = bt_learn, task = predictMoa, resampling = outer, extract = getFeatureImportance, models = T, measures = list(mmce, kappa, multiclass_mcc)))

system.time( expr = eval(bt_expr))
```


***

# System and session info

```{r}
R.version
sessionInfo()
```

